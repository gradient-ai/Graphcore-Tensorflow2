{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2a82e28",
   "metadata": {},
   "source": [
    "Copyright (c) 2022 Graphcore Ltd. All rights reserved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d138b5d",
   "metadata": {},
   "source": [
    "Copyright 2022 The Google Research Authors.\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "    http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcf6e44",
   "metadata": {},
   "source": [
    "# Running Cluster GCN Step by Step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca08d5c4",
   "metadata": {},
   "source": [
    "In this tutorial we show how to train the Cluster-GCN algorithm,\n",
    "presented in [Cluster-GCN: An Efficient Algorithm for Training Deep and Large Graph Convolutional\n",
    "Networks](https://arxiv.org/pdf/1905.07953.pdf), on the Graphcore IPU.\n",
    "\n",
    "In this tutorial, you will learn how to train and test the model step by step, including:\n",
    "\n",
    "- Load the data.\n",
    "- Configure the IPU.\n",
    "- Create a strategy.\n",
    "- Create the model.\n",
    "- Train and test the model.\n",
    "\n",
    "[1] Wei-Lin Chiang, Xuanqing Liu, Si Si, Yang Li, Samy Bengio, Cho-Jui Hsieh,\n",
    "\"Cluster-GCN An Efficient Algorithm for Training Deep and Large Graph Convolutional Networks,\"\n",
    "KDD '19: Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &\n",
    "Data Mining, July 2019, Pages 257–266, https://doi.org/10.1145/3292500.3330925"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5f0e4d",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Cluster GCN can be considered a sampling method that allows to train on large scale graph machine learning datasets. Cluster GCN works on two steps. First, it clusters the data, such that each cluster is a subgraph. Second, the algorithm trains the model using a stochastic gradient estimated with a batch of sampled subgraphs.\n",
    "\n",
    "By default, we will train with the [arXiv dataset](https://ogb.stanford.edu/docs/nodeprop/#ogbn-arxiv), which is a directed homogeneous graph encoding a citation network between all Computer Science (CS) papers hosted in arXiv and indexed by the Microsoft academic graph (MAG). Each paper has a 128-dimmensional node feature vector, that encodes the title and abstract, processed with a skip-gram model. Each directed link in the graph indicates that one paper cites another. The task is to predict the correct topic label for the paper from the 40 main categories. The train portion of the dataset is all papers published until 2017, the papers published in 2018 are the validation set, and papers published in 2019 are the test set. We wukk use the arXiv dataset, simply use the train_arxiv.json config, the dataset will be downloaded automatically.\n",
    "\n",
    "We will also show how to train with other common datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800892b4",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eafc614-3c97-43df-a82c-a37c13a30b23",
   "metadata": {},
   "source": [
    "Requirements:\n",
    "\n",
    "- Paperspace account with access to the PyTorch IPU runtime\n",
    "- APT and Python packages as installed below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96546863",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-12T00:01:58.972962Z",
     "iopub.status.busy": "2022-08-12T00:01:58.972528Z",
     "iopub.status.idle": "2022-08-12T00:03:01.829083Z",
     "shell.execute_reply": "2022-08-12T00:03:01.828420Z",
     "shell.execute_reply.started": "2022-08-12T00:01:58.972880Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get:1 http://archive.ubuntu.com/ubuntu focal InRelease [265 kB]\n",
      "Get:2 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n",
      "Get:5 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [2087 kB]\n",
      "Get:6 http://archive.ubuntu.com/ubuntu focal/restricted amd64 Packages [33.4 kB]\n",
      "Get:7 http://archive.ubuntu.com/ubuntu focal/universe amd64 Packages [11.3 MB] \n",
      "Get:8 http://security.ubuntu.com/ubuntu focal-security/multiverse amd64 Packages [27.5 kB]\n",
      "Get:9 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [888 kB]\n",
      "Get:10 http://security.ubuntu.com/ubuntu focal-security/restricted amd64 Packages [1461 kB]\n",
      "Get:11 http://archive.ubuntu.com/ubuntu focal/main amd64 Packages [1275 kB]    \n",
      "Get:12 http://archive.ubuntu.com/ubuntu focal/multiverse amd64 Packages [177 kB]\n",
      "Get:13 http://archive.ubuntu.com/ubuntu focal-updates/restricted amd64 Packages [1569 kB]\n",
      "Get:14 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [2539 kB]\n",
      "Get:15 http://archive.ubuntu.com/ubuntu focal-updates/multiverse amd64 Packages [30.2 kB]\n",
      "Get:16 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1176 kB]\n",
      "Get:17 http://archive.ubuntu.com/ubuntu focal-backports/main amd64 Packages [55.2 kB]\n",
      "Get:18 http://archive.ubuntu.com/ubuntu focal-backports/universe amd64 Packages [27.5 kB]\n",
      "Fetched 23.3 MB in 1s (15.6 MB/s)                      \n",
      "Reading package lists... Done\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following additional packages will be installed:\n",
      "  libmetis5\n",
      "The following NEW packages will be installed:\n",
      "  libmetis-dev libmetis5\n",
      "0 upgraded, 2 newly installed, 0 to remove and 32 not upgraded.\n",
      "Need to get 175 kB of archives.\n",
      "After this operation, 494 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu focal/main amd64 libmetis5 amd64 5.1.0.dfsg-5 [169 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu focal/main amd64 libmetis-dev amd64 5.1.0.dfsg-5 [5794 B]\n",
      "Fetched 175 kB in 1s (284 kB/s)       \n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 2.)\n",
      "debconf: falling back to frontend: Readline\n",
      "Selecting previously unselected package libmetis5:amd64.\n",
      "(Reading database ... 47201 files and directories currently installed.)\n",
      "Preparing to unpack .../libmetis5_5.1.0.dfsg-5_amd64.deb ...\n",
      "Unpacking libmetis5:amd64 (5.1.0.dfsg-5) ...\n",
      "Selecting previously unselected package libmetis-dev.\n",
      "Preparing to unpack .../libmetis-dev_5.1.0.dfsg-5_amd64.deb ...\n",
      "Unpacking libmetis-dev (5.1.0.dfsg-5) ...\n",
      "Setting up libmetis5:amd64 (5.1.0.dfsg-5) ...\n",
      "Setting up libmetis-dev (5.1.0.dfsg-5) ...\n",
      "Processing triggers for libc-bin (2.31-0ubuntu9.2) ...\n",
      "Collecting examples-utils\n",
      "  Cloning https://github.com/graphcore/examples-utils (to revision 6d3b8367d5c6d2cda5a0e7849138d0ee8a8c6756) to /tmp/pip-install-uxv5wx3q/examples-utils_9defd2084ff1475a9bed59ac013f61dc\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/graphcore/examples-utils /tmp/pip-install-uxv5wx3q/examples-utils_9defd2084ff1475a9bed59ac013f61dc\n",
      "  Running command git rev-parse -q --verify 'sha^6d3b8367d5c6d2cda5a0e7849138d0ee8a8c6756'\n",
      "  Running command git fetch -q https://github.com/graphcore/examples-utils 6d3b8367d5c6d2cda5a0e7849138d0ee8a8c6756\n",
      "  Running command git checkout -q 6d3b8367d5c6d2cda5a0e7849138d0ee8a8c6756\n",
      "  Resolved https://github.com/graphcore/examples-utils to commit 6d3b8367d5c6d2cda5a0e7849138d0ee8a8c6756\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting metis==0.2a5\n",
      "  Downloading metis-0.2a5.tar.gz (10 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting networkx==2.5.1\n",
      "  Downloading networkx-2.5.1-py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting ogb==1.3.3\n",
      "  Downloading ogb-1.3.3-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.2/78.2 kB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting plotly==5.7.0\n",
      "  Downloading plotly-5.7.0-py2.py3-none-any.whl (28.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.8/28.8 MB\u001b[0m \u001b[31m62.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pydantic==1.9.0\n",
      "  Downloading pydantic-1.9.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.6/12.6 MB\u001b[0m \u001b[31m79.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pytest==6.2.5\n",
      "  Downloading pytest-6.2.5-py3-none-any.whl (280 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.7/280.7 kB\u001b[0m \u001b[31m75.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pytest-cov==3.0.0\n",
      "  Downloading pytest_cov-3.0.0-py3-none-any.whl (20 kB)\n",
      "Collecting pytest-forked==1.4.0\n",
      "  Downloading pytest_forked-1.4.0-py3-none-any.whl (4.9 kB)\n",
      "Collecting pytest-mock==3.6.1\n",
      "  Downloading pytest_mock-3.6.1-py3-none-any.whl (12 kB)\n",
      "Collecting pytest-pythonpath==0.7.4\n",
      "  Downloading pytest_pythonpath-0.7.4-py3-none-any.whl (3.7 kB)\n",
      "Collecting pytest-xdist==2.5.0\n",
      "  Downloading pytest_xdist-2.5.0-py3-none-any.whl (41 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting regex==2022.4.24\n",
      "  Downloading regex-2022.4.24-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (764 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m764.9/764.9 kB\u001b[0m \u001b[31m93.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting scipy==1.5.4\n",
      "  Downloading scipy-1.5.4-cp38-cp38-manylinux1_x86_64.whl (25.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.8/25.8 MB\u001b[0m \u001b[31m67.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting scikit-learn==0.24.2\n",
      "  Downloading scikit_learn-0.24.2-cp38-cp38-manylinux2010_x86_64.whl (24.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.9/24.9 MB\u001b[0m \u001b[31m70.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow-addons==0.14.0\n",
      "  Downloading tensorflow_addons-0.14.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m72.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting trainlog==0.2\n",
      "  Downloading trainlog-0.2-py3-none-any.whl (16 kB)\n",
      "Collecting wandb==0.12.8\n",
      "  Downloading wandb-0.12.8-py2.py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m79.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting decorator<5,>=4.3\n",
      "  Downloading decorator-4.4.2-py2.py3-none-any.whl (9.2 kB)\n",
      "Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.8/dist-packages (from ogb==1.3.3->-r requirements.txt (line 3)) (1.26.11)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from ogb==1.3.3->-r requirements.txt (line 3)) (1.15.0)\n",
      "Collecting torch>=1.6.0\n",
      "  Downloading torch-1.12.1-cp38-cp38-manylinux1_x86_64.whl (776.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.3/776.3 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pandas>=0.24.0\n",
      "  Downloading pandas-1.4.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m75.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0mm\n",
      "\u001b[?25hCollecting tqdm>=4.29.0\n",
      "  Downloading tqdm-4.64.0-py2.py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting outdated>=0.2.0\n",
      "  Downloading outdated-0.2.1-py3-none-any.whl (7.5 kB)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.8/dist-packages (from ogb==1.3.3->-r requirements.txt (line 3)) (1.19.5)\n",
      "Collecting tenacity>=6.2.0\n",
      "  Downloading tenacity-8.0.1-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from pydantic==1.9.0->-r requirements.txt (line 5)) (3.10.0.2)\n",
      "Collecting py>=1.8.2\n",
      "  Downloading py-1.11.0-py2.py3-none-any.whl (98 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 kB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from pytest==6.2.5->-r requirements.txt (line 6)) (21.3)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.8/dist-packages (from pytest==6.2.5->-r requirements.txt (line 6)) (22.1.0)\n",
      "Collecting toml\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Collecting iniconfig\n",
      "  Downloading iniconfig-1.1.1-py2.py3-none-any.whl (5.0 kB)\n",
      "Collecting pluggy<2.0,>=0.12\n",
      "  Downloading pluggy-1.0.0-py2.py3-none-any.whl (13 kB)\n",
      "Collecting coverage[toml]>=5.2.1\n",
      "  Downloading coverage-6.4.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.7/213.7 kB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting execnet>=1.1\n",
      "  Downloading execnet-1.9.0-py2.py3-none-any.whl (39 kB)\n",
      "Collecting joblib>=0.11\n",
      "  Downloading joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.0/307.0 kB\u001b[0m \u001b[31m69.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Collecting typeguard>=2.7\n",
      "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
      "Collecting configparser>=3.8.1\n",
      "  Downloading configparser-5.2.0-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from wandb==0.12.8->-r requirements.txt (line 17)) (5.4.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.8/dist-packages (from wandb==0.12.8->-r requirements.txt (line 17)) (2.8.2)\n",
      "Collecting Click!=8.0.0,>=7.0\n",
      "  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.6/96.6 kB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting sentry-sdk>=1.0.0\n",
      "  Downloading sentry_sdk-1.9.4-py2.py3-none-any.whl (157 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.6/157.6 kB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting docker-pycreds>=0.4.0\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from wandb==0.12.8->-r requirements.txt (line 17)) (2.28.1)\n",
      "Collecting shortuuid>=0.5.0\n",
      "  Downloading shortuuid-1.0.9-py3-none-any.whl (9.4 kB)\n",
      "Collecting yaspin>=1.0.0\n",
      "  Downloading yaspin-2.2.0-py3-none-any.whl (18 kB)\n",
      "Collecting pathtools\n",
      "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting subprocess32>=3.5.3\n",
      "  Downloading subprocess32-3.5.4.tar.gz (97 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.4/97.4 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.8/dist-packages (from wandb==0.12.8->-r requirements.txt (line 17)) (3.19.4)\n",
      "Collecting psutil>=5.0.0\n",
      "  Downloading psutil-5.9.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (284 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.7/284.7 kB\u001b[0m \u001b[31m72.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting promise<3,>=2.0\n",
      "  Downloading promise-2.3.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting GitPython>=1.0.0\n",
      "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.2/181.2 kB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting filelock\n",
      "  Downloading filelock-3.8.0-py3-none-any.whl (10 kB)\n",
      "Collecting cppimport==21.3.7\n",
      "  Downloading cppimport-21.3.7.tar.gz (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m75.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting psutil>=5.0.0\n",
      "  Downloading psutil-5.7.0.tar.gz (449 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m449.6/449.6 kB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pybind11\n",
      "  Downloading pybind11-2.10.0-py3-none-any.whl (213 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.3/213.3 kB\u001b[0m \u001b[31m62.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting mako\n",
      "  Downloading Mako-1.2.1-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tomli\n",
      "  Downloading tomli-2.0.1-py3-none-any.whl (12 kB)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting littleutils\n",
      "  Downloading littleutils-0.2.2.tar.gz (6.6 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.24.0->ogb==1.3.3->-r requirements.txt (line 3)) (2022.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb==0.12.8->-r requirements.txt (line 17)) (2022.6.15)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb==0.12.8->-r requirements.txt (line 17)) (2.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb==0.12.8->-r requirements.txt (line 17)) (3.3)\n",
      "Collecting termcolor-whl==1.1.2\n",
      "  Downloading termcolor_whl-1.1.2-py2.py3-none-any.whl (4.8 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->pytest==6.2.5->-r requirements.txt (line 6)) (3.0.9)\n",
      "Collecting smmap<6,>=3.0.1\n",
      "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.8/dist-packages (from mako->cppimport==21.3.7->examples-utils->-r requirements.txt (line 18)) (2.1.1)\n",
      "Building wheels for collected packages: metis, examples-utils, cppimport, psutil, promise, subprocess32, pathtools, littleutils\n",
      "  Building wheel for metis (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for metis: filename=metis-0.2a5-py3-none-any.whl size=11306 sha256=fca388d207fea59aa7383c1bd83c2210ea42bd252e1005e52cbb6e2c28fee575\n",
      "  Stored in directory: /root/.cache/pip/wheels/29/49/4e/230b38868b5ffaeef46a5ba311f9d0a72cedca6a7254acaab8\n",
      "  Building wheel for examples-utils (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for examples-utils: filename=examples_utils-0.0.0-py3-none-any.whl size=30457 sha256=65ca1815a5bc9df43da3f3e41c76c9acfe9e3d2207cbd1f833148aca67ad85d9\n",
      "  Stored in directory: /root/.cache/pip/wheels/f3/0f/7a/9f7d978cb453e477b853a352e673546a03e7b6fd024fd88f94\n",
      "  Building wheel for cppimport (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for cppimport: filename=cppimport-21.3.7-py3-none-any.whl size=13184 sha256=81608acbed8aecb139d34ec0a0c0f9ff5fef0aee17515bd8a0e5dc932ac0fba4\n",
      "  Stored in directory: /root/.cache/pip/wheels/15/23/05/207230afd77873d411964444c96becec609ab3253e72a87d85\n",
      "  Building wheel for psutil (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for psutil: filename=psutil-5.7.0-cp38-cp38-linux_x86_64.whl size=286108 sha256=1430a561abcee43bd452a9f48424fcd7e27f817408d406160592529b3ada8bb4\n",
      "  Stored in directory: /root/.cache/pip/wheels/90/c9/b6/04665702b01dbd9ee92a05e834b627948ed01cdd482e6a78e1\n",
      "  Building wheel for promise (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21486 sha256=6f278f6c0e911e1e8f738aee2691a4fde55cf78ad24cf00ff2fdce135cec0571\n",
      "  Stored in directory: /root/.cache/pip/wheels/54/aa/01/724885182f93150035a2a91bce34a12877e8067a97baaf5dc8\n",
      "  Building wheel for subprocess32 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for subprocess32: filename=subprocess32-3.5.4-py3-none-any.whl size=6488 sha256=d75583d049bd5f8cc9094f3fdb0bca8497be737a38988d39b161358ede65723c\n",
      "  Stored in directory: /root/.cache/pip/wheels/9f/69/d1/50b39b308a87998eaf5c1d9095e5a5bd2ad98501e2b7936d36\n",
      "  Building wheel for pathtools (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8792 sha256=3aa359cc8f149520902317a80ce6b8c2b8fff09818d6530e477b9a67f4bc10eb\n",
      "  Stored in directory: /root/.cache/pip/wheels/4c/8e/7e/72fbc243e1aeecae64a96875432e70d4e92f3d2d18123be004\n",
      "  Building wheel for littleutils (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for littleutils: filename=littleutils-0.2.2-py3-none-any.whl size=7028 sha256=92a333de2e361911b1ab5e83a366ec1e91ad91214f831812e04feb009999ea77\n",
      "  Stored in directory: /root/.cache/pip/wheels/6a/33/c4/0ef84d7f5568c2823e3d63a6e08988852fb9e4bc822034870a\n",
      "Successfully built metis examples-utils cppimport psutil promise subprocess32 pathtools littleutils\n",
      "Installing collected packages: trainlog, pathtools, metis, littleutils, iniconfig, typeguard, tqdm, torch, tomli, toml, threadpoolctl, termcolor-whl, tenacity, subprocess32, smmap, shortuuid, sentry-sdk, scipy, regex, pydantic, pybind11, py, psutil, promise, pluggy, mako, joblib, filelock, execnet, docker-pycreds, decorator, coverage, configparser, Click, yaspin, tensorflow-addons, scikit-learn, pytest, plotly, pandas, outdated, networkx, gitdb, cppimport, pytest-pythonpath, pytest-mock, pytest-forked, pytest-cov, ogb, GitPython, examples-utils, wandb, pytest-xdist\n",
      "  Attempting uninstall: decorator\n",
      "    Found existing installation: decorator 5.1.1\n",
      "    Uninstalling decorator-5.1.1:\n",
      "      Successfully uninstalled decorator-5.1.1\n",
      "Successfully installed Click-8.1.3 GitPython-3.1.27 configparser-5.2.0 coverage-6.4.3 cppimport-21.3.7 decorator-4.4.2 docker-pycreds-0.4.0 examples-utils-0.0.0 execnet-1.9.0 filelock-3.8.0 gitdb-4.0.9 iniconfig-1.1.1 joblib-1.1.0 littleutils-0.2.2 mako-1.2.1 metis-0.2a5 networkx-2.5.1 ogb-1.3.3 outdated-0.2.1 pandas-1.4.3 pathtools-0.1.2 plotly-5.7.0 pluggy-1.0.0 promise-2.3 psutil-5.7.0 py-1.11.0 pybind11-2.10.0 pydantic-1.9.0 pytest-6.2.5 pytest-cov-3.0.0 pytest-forked-1.4.0 pytest-mock-3.6.1 pytest-pythonpath-0.7.4 pytest-xdist-2.5.0 regex-2022.4.24 scikit-learn-0.24.2 scipy-1.5.4 sentry-sdk-1.9.4 shortuuid-1.0.9 smmap-5.0.0 subprocess32-3.5.4 tenacity-8.0.1 tensorflow-addons-0.14.0 termcolor-whl-1.1.2 threadpoolctl-3.1.0 toml-0.10.2 tomli-2.0.1 torch-1.12.1 tqdm-4.64.0 trainlog-0.2 typeguard-2.13.3 wandb-0.12.8 yaspin-2.2.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "!apt-get update\n",
    "!apt-get install -y libmetis-dev=5.1.0.dfsg-5\n",
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "067183eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-12T00:03:01.830486Z",
     "iopub.status.busy": "2022-08-12T00:03:01.830288Z",
     "iopub.status.idle": "2022-08-12T00:03:06.145571Z",
     "shell.execute_reply": "2022-08-12T00:03:06.144662Z",
     "shell.execute_reply.started": "2022-08-12T00:03:01.830463Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loading Horovod library: /usr/local/lib/python3.8/dist-packages/tensorflow/python/ipu/horovod/horovod_plugin.so\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import json\n",
    "import logging\n",
    "\n",
    "from pprint import pformat\n",
    "\n",
    "import numpy as np\n",
    "import popdist.tensorflow\n",
    "import tensorflow as tf\n",
    "\n",
    "from data_utils.batch_config import BatchConfig\n",
    "from data_utils.clustering_utils import ClusterGraph\n",
    "from data_utils.clustering_statistics import ClusteringStatistics\n",
    "from data_utils.dataset_batch_generator import tf_dataset_generator\n",
    "from data_utils.dataset_loader import load_dataset\n",
    "from keras_extensions.callbacks.callback_factory import CallbackFactory\n",
    "from keras_extensions.optimization import get_optimizer\n",
    "from model.loss_accuracy import get_loss_and_metrics\n",
    "from model.model import create_model\n",
    "from model.pipeline_stage_names import (\n",
    "    PIPELINE_ALLOCATE_PREVIOUS,\n",
    "    PIPELINE_NAMES\n",
    ")\n",
    "from model.precision import Precision\n",
    "from utilities.constants import GraphType\n",
    "from utilities.ipu_utils import create_ipu_strategy, set_random_seeds\n",
    "from utilities.options import Options\n",
    "from utilities.pipeline_stage_assignment import pipeline_model\n",
    "from utilities.utils import (\n",
    "    get_adjacency_dtype,\n",
    "    get_adjacency_form,\n",
    "    get_method_max\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127674bb",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48077e79",
   "metadata": {},
   "source": [
    "Setup logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a45c5fc5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-12T00:03:06.148853Z",
     "iopub.status.busy": "2022-08-12T00:03:06.147577Z",
     "iopub.status.idle": "2022-08-12T00:03:06.152645Z",
     "shell.execute_reply": "2022-08-12T00:03:06.152101Z",
     "shell.execute_reply.started": "2022-08-12T00:03:06.148834Z"
    }
   },
   "outputs": [],
   "source": [
    "logging.getLogger().setLevel(\"INFO\")\n",
    "logging.basicConfig(format=\"%(asctime)s %(levelname)-8s %(message)s\",\n",
    "                    datefmt=\"%Y-%m-%d %H:%M:%S\")\n",
    "# Prevent doubling of TF logs.\n",
    "tf.get_logger().propagate = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a895efd3",
   "metadata": {},
   "source": [
    "Define config file and use default values for those not defined in the config file.\n",
    "By default, we will use a config file for the arXiv dataset.\n",
    "\n",
    "But we encourage you to experiment with the other example files we provide too:\n",
    "\n",
    "- configs/train_arxiv.json\n",
    "- configs/train_mag.json\n",
    "- configs/train_mag240.json\n",
    "- configs/train_ppi.json\n",
    "- configs/train_products.json\n",
    "- configs/train_reddit.json\n",
    "\n",
    "Note that the PPI and Reddit datasets have to be downloaded manually from [Stanford GraphSAGE](https://snap.stanford.edu/graphsage/). The rest of datasets will download automatically. Note also some datasets, like Products and MAG, can take long to download, preprocess and clustering. The MAG240 dataset can take several hours for this preprocessing.  Moreover, note that the clustering method used in the original paper [1] -and also the one implemented here- has been designed for homogeneous graphs. However, two of the config files described above, namely `configs/train_mag.json` and `configs/train_mag240.json` that correspond with MAG and MAG240 datasets, respectively, include heterogeneous graphs. Hence, clustering these datasets as if they were homogeneous graphs can reduce the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "444bf196",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-12T00:03:06.153880Z",
     "iopub.status.busy": "2022-08-12T00:03:06.153708Z",
     "iopub.status.idle": "2022-08-12T00:03:06.187792Z",
     "shell.execute_reply": "2022-08-12T00:03:06.187171Z",
     "shell.execute_reply.started": "2022-08-12T00:03:06.153864Z"
    }
   },
   "outputs": [],
   "source": [
    "config_file = \"configs/train_arxiv.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bd96575",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-12T00:03:06.188866Z",
     "iopub.status.busy": "2022-08-12T00:03:06.188572Z",
     "iopub.status.idle": "2022-08-12T00:03:06.196950Z",
     "shell.execute_reply": "2022-08-12T00:03:06.196392Z",
     "shell.execute_reply.started": "2022-08-12T00:03:06.188849Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-12 00:03:06 WARNING  'diag_lambda' parameter from config will not be used.\n",
      "2022-08-12 00:03:06 WARNING  Requested to run on CPU device for ValidationOptions. The IPU config options will be ignored, and any IPU specific layers will be replaced with their generic equivalent.\n",
      "2022-08-12 00:03:06 WARNING  Requested to run on CPU device for TestOptions. The IPU config options will be ignored, and any IPU specific layers will be replaced with their generic equivalent.\n",
      "2022-08-12 00:03:06 INFO     Config: {'calculate_cluster_statistics': False,\n",
      " 'cluster_node_edge_imbalance_ratio': None,\n",
      " 'compile_only': False,\n",
      " 'data_path': 'data',\n",
      " 'dataset_name': 'ogbn-arxiv',\n",
      " 'do_test': True,\n",
      " 'do_training': True,\n",
      " 'do_validation': True,\n",
      " 'executions_per_ckpt': 0,\n",
      " 'executions_per_log': 1,\n",
      " 'fp_exceptions': False,\n",
      " 'inter_cluster_ratio': 0.0,\n",
      " 'load_ckpt_path': None,\n",
      " 'logging': 'INFO',\n",
      " 'method_max_edges': 'upper_bound',\n",
      " 'method_max_nodes': 'upper_bound',\n",
      " 'model': {'adjacency': {'diag_lambda': -1.0,\n",
      "                         'regularisation': None,\n",
      "                         'transform_mode': 'normalised'},\n",
      "           'dropout': 0.4,\n",
      "           'first_layer_precalculation': True,\n",
      "           'hidden_size': 256,\n",
      "           'num_layers': 5},\n",
      " 'name': 'Cluster-GCN',\n",
      " 'pca_features_path': None,\n",
      " 'regenerate_clustering_cache': False,\n",
      " 'regenerate_dataset_cache': False,\n",
      " 'save_ckpt_path': PosixPath('/notebooks/get-started/checkpoints'),\n",
      " 'save_clustering_cache': True,\n",
      " 'save_dataset_cache': True,\n",
      " 'seed': 1984,\n",
      " 'test': {'clusters_per_batch': 20,\n",
      "          'dataset_prefetch_depth': 10,\n",
      "          'device': 'cpu',\n",
      "          'epochs_per_execution': 1,\n",
      "          'executions_per_epoch': 1,\n",
      "          'gradient_accumulation_steps_per_replica': 1,\n",
      "          'ipu_config': {'enable_recomputation': False,\n",
      "                         'matmul_available_memory_proportion_per_pipeline_stage': [0.3],\n",
      "                         'num_io_tiles': 0,\n",
      "                         'pipeline_device_mapping': [0],\n",
      "                         'pipeline_stages': [['adj_proc',\n",
      "                                              'hid',\n",
      "                                              'hid',\n",
      "                                              'hid',\n",
      "                                              'hid',\n",
      "                                              'hid']]},\n",
      "          'max_nodes_per_batch': None,\n",
      "          'micro_batch_size': 1,\n",
      "          'num_clusters': 1500,\n",
      "          'precision': 'fp32',\n",
      "          'replicas': 1,\n",
      "          'use_sparse_representation': True},\n",
      " 'training': {'clusters_per_batch': 50,\n",
      "              'dataset_prefetch_depth': 10,\n",
      "              'device': 'ipu',\n",
      "              'do_live_validation': False,\n",
      "              'epochs': 200,\n",
      "              'epochs_per_execution': 1,\n",
      "              'executions_per_epoch': 1,\n",
      "              'gradient_accumulation_steps_per_replica': 1,\n",
      "              'ipu_config': {'enable_recomputation': False,\n",
      "                             'matmul_available_memory_proportion_per_pipeline_stage': [0.3],\n",
      "                             'num_io_tiles': 128,\n",
      "                             'pipeline_device_mapping': [0],\n",
      "                             'pipeline_stages': [['adj_proc',\n",
      "                                                  'hid',\n",
      "                                                  'hid',\n",
      "                                                  'hid',\n",
      "                                                  'hid',\n",
      "                                                  'hid']]},\n",
      "              'loss_scaling': 1000,\n",
      "              'lr': 0.005,\n",
      "              'max_nodes_per_batch': None,\n",
      "              'micro_batch_size': 1,\n",
      "              'num_clusters': 1500,\n",
      "              'precision': 'fp16',\n",
      "              'replicas': 1,\n",
      "              'use_sparse_representation': True,\n",
      "              'validation_frequency': 10},\n",
      " 'validation': {'clusters_per_batch': 20,\n",
      "                'dataset_prefetch_depth': 10,\n",
      "                'device': 'cpu',\n",
      "                'epochs_per_execution': 1,\n",
      "                'executions_per_epoch': 1,\n",
      "                'gradient_accumulation_steps_per_replica': 1,\n",
      "                'ipu_config': {'enable_recomputation': False,\n",
      "                               'matmul_available_memory_proportion_per_pipeline_stage': [0.3],\n",
      "                               'num_io_tiles': 0,\n",
      "                               'pipeline_device_mapping': [0],\n",
      "                               'pipeline_stages': [['adj_proc',\n",
      "                                                    'hid',\n",
      "                                                    'hid',\n",
      "                                                    'hid',\n",
      "                                                    'hid',\n",
      "                                                    'hid']]},\n",
      "                'max_nodes_per_batch': None,\n",
      "                'micro_batch_size': 1,\n",
      "                'num_clusters': 1500,\n",
      "                'precision': 'fp32',\n",
      "                'replicas': 1,\n",
      "                'use_sparse_representation': True},\n",
      " 'wandb': True}\n"
     ]
    }
   ],
   "source": [
    "with open(config_file, \"r\") as read_file:\n",
    "    config = json.load(read_file)\n",
    "config = Options(**config)\n",
    "\n",
    "logging.info(f\"Config: {pformat(config.dict())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb454ca6",
   "metadata": {},
   "source": [
    "We disable logging results in Weights and Biases by overwriting the `config.wandb` parameter from the config file and set it to false."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08e43f34",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-12T00:03:06.197858Z",
     "iopub.status.busy": "2022-08-12T00:03:06.197690Z",
     "iopub.status.idle": "2022-08-12T00:03:06.200484Z",
     "shell.execute_reply": "2022-08-12T00:03:06.199826Z",
     "shell.execute_reply.started": "2022-08-12T00:03:06.197842Z"
    }
   },
   "outputs": [],
   "source": [
    "config.wandb = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d4a234",
   "metadata": {},
   "source": [
    "### Training configuration\n",
    "\n",
    "Set training precision and the way we represent the adjacency matrix from the config file. For the model precision we can choose FP32 or FP16; while for the representation of the adjacency matrix, we can choose either dense or the COO sparse representation.\n",
    "\n",
    "You can also override the precision configuration in the code. For example, in order to set FP16 and COO representation just do the following:\n",
    "```\n",
    "config.training.precision = \"fp16\"\n",
    "config.training.use_sparse_representation = True\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ca26262",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-12T00:03:06.201413Z",
     "iopub.status.busy": "2022-08-12T00:03:06.201235Z",
     "iopub.status.idle": "2022-08-12T00:03:06.205294Z",
     "shell.execute_reply": "2022-08-12T00:03:06.204723Z",
     "shell.execute_reply.started": "2022-08-12T00:03:06.201397Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set precision policy for training\n",
    "precision = Precision(config.training.precision)\n",
    "tf.keras.mixed_precision.set_global_policy(precision.policy)\n",
    "\n",
    "# Set how the adjacency matrix is expressed,\n",
    "# namely dense (tf.Tensor), dynamic COO representation (tf.sparse.SparseTensor),\n",
    "# or static COO representation with padding (tuple).\n",
    "adjacency_form_training = get_adjacency_form(\n",
    "    config.training.device,\n",
    "    config.training.use_sparse_representation)\n",
    "\n",
    "# Decide on the dtype of the adjacency matrix\n",
    "adjacency_dtype_training = get_adjacency_dtype(\n",
    "    config.training.device,\n",
    "    config.training.use_sparse_representation)\n",
    "\n",
    "method_max_edges = get_method_max(config.method_max_edges)\n",
    "method_max_nodes = get_method_max(config.method_max_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8eaac03",
   "metadata": {},
   "source": [
    "Set a unique name for this training run. This is useful when logging data, especially when logging the results on Weights and Biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2413d77e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-12T00:03:06.207709Z",
     "iopub.status.busy": "2022-08-12T00:03:06.207538Z",
     "iopub.status.idle": "2022-08-12T00:03:06.211326Z",
     "shell.execute_reply": "2022-08-12T00:03:06.210785Z",
     "shell.execute_reply.started": "2022-08-12T00:03:06.207694Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-12 00:03:06 INFO     Universal name for run: Cluster-GCN-ogbn-arxiv-fp16-ipu-AdjacencyForm.SPARSE_TUPLE-20220812_000306\n"
     ]
    }
   ],
   "source": [
    "time_now = datetime.now().timestamp()\n",
    "universal_run_name = (\n",
    "    f\"{config.name}-\"\n",
    "    f\"{config.dataset_name}-\"\n",
    "    f\"{config.training.precision}-\"\n",
    "    f\"{config.training.device}-\"\n",
    "    f\"{adjacency_form_training}-\"\n",
    "    f\"{datetime.fromtimestamp(time_now).strftime('%Y%m%d_%H%M%S')}\"\n",
    ")\n",
    "logging.info(f\"Universal name for run: {universal_run_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d1205c",
   "metadata": {},
   "source": [
    "## Load the dataset\n",
    "\n",
    "We are now ready to load the dataset. We only have to introduce the path to the dataset. This path will be used to look for available preprocessed data and cached clustering results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc5eee85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-12T00:03:06.212722Z",
     "iopub.status.busy": "2022-08-12T00:03:06.212555Z",
     "iopub.status.idle": "2022-08-12T00:03:06.215254Z",
     "shell.execute_reply": "2022-08-12T00:03:06.214626Z",
     "shell.execute_reply.started": "2022-08-12T00:03:06.212706Z"
    }
   },
   "outputs": [],
   "source": [
    "config.data_path = \"graph_datasets/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f0d6d4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-12T00:03:06.216201Z",
     "iopub.status.busy": "2022-08-12T00:03:06.216035Z",
     "iopub.status.idle": "2022-08-12T00:03:41.921555Z",
     "shell.execute_reply": "2022-08-12T00:03:41.920771Z",
     "shell.execute_reply.started": "2022-08-12T00:03:06.216185Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-12 00:03:06 INFO     Loading raw dataset...\n",
      "2022-08-12 00:03:06 INFO     Loading OGB dataset ogbn-arxiv.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://snap.stanford.edu/ogb/data/nodeproppred/arxiv.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloaded 0.08 GB: 100%|██████████| 81/81 [00:05<00:00, 16.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting graph_datasets/arxiv.zip\n",
      "Loading necessary files...\n",
      "This might take a while.\n",
      "Processing graphs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 2111.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2022-08-12 00:03:18 INFO     Raw dataset loaded.\n",
      "2022-08-12 00:03:18 INFO     Preprocessing dataset...\n",
      "2022-08-12 00:03:18 INFO     Generating adjacency matrices in dataset with dtype <class 'bool'>...\n",
      "2022-08-12 00:03:18 INFO     Generating masks in dataset...\n",
      "2022-08-12 00:03:18 INFO     Normalizing the features in dataset...\n",
      "2022-08-12 00:03:18 INFO     Precalculating the first layer features in dataset...\n",
      "2022-08-12 00:03:19 INFO     Removing undirected connections in dataset...\n",
      "2022-08-12 00:03:19 INFO     Removing self connections in dataset...\n",
      "2022-08-12 00:03:19 INFO     Casting the features in dataset to dtype float16...\n",
      "2022-08-12 00:03:19 INFO     Casting the labels in dataset to dtype int32...\n",
      "2022-08-12 00:03:19 INFO     Dataset preprocessed.\n",
      "2022-08-12 00:03:19 INFO     Saving processed dataset to /notebooks/get-started/graph_datasets/ogbn-arxiv_preprocessed_normalized_True_precalc_True_adjdtype_bool_featdtype_float16_labelsdtype_int32.pickle.gz...\n",
      "2022-08-12 00:03:41 INFO     Graph dataset: HomogeneousGraphDataset(\n",
      "\tName: ogbn-arxiv,\n",
      "\tNum features: 256,\n",
      "\tNum labels: 40,\n",
      "\tTotal num nodes: 169343,\n",
      "\tNum nodes: {'train': 90941, 'validation': 29799, 'test': 48603},\n",
      "\tNum edges: {'train': 374839, 'validation': 1166243, 'test': 1166243},\n",
      "\tGraph type: GraphType.DIRECTED,\n",
      "\tTask: Task.MULTI_CLASS_CLASSIFICATION)\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\n",
    "        dataset_path=config.data_path,\n",
    "        dataset_name=config.dataset_name,\n",
    "        precalculate_first_layer=config.model.first_layer_precalculation,\n",
    "        adjacency_dtype=adjacency_dtype_training,\n",
    "        features_dtype=precision.features_precision.as_numpy_dtype,\n",
    "        labels_dtype=precision.labels_precision.as_numpy_dtype,\n",
    "        regenerate_cache=config.regenerate_dataset_cache,\n",
    "        save_dataset_cache=config.save_dataset_cache,\n",
    "        pca_features_path=config.pca_features_path,\n",
    "    )\n",
    "logging.info(f\"Graph dataset: {dataset}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521df147",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "### Clustering the training dataset\n",
    "\n",
    "Once we have loaded the dataset, we can cluster the associated graph, using the parameters given in the config file, mainly `config.training.num_clusters` or `config.training.max_nodes_per_batch`. The former sets the total number of clusters in which we want to split the graph. The latter specifies the maximum number of nodes per cluster. Note these are alternative methods, so we cannot specify both parameters.\n",
    "\n",
    "Other important parameters are:\n",
    "- `config.training.clusters_per_batch`: Number of clusters to be processed together in a micro-batch.\n",
    "\n",
    "- `method_max_nodes` and `method_max_edges`: In order to maximise bandwidth, we compile the model as a static graph. This requires having static datastructures. Since the number of nodes can change from one cluster to another, we need a method to set the maximum number of nodes per cluster. If a cluster has a number of nodes smaller than what we have defined, then it will pad with a dummy node so that it fits the allocated memory, wasting computations and reducing throughput. On the other hand, if they are larger, it will remove some of them so that they fit in the allocated space, removing data and potentially reducing accuracy. Though there is a tradeoff here, and we offer three methods to optimise this tradeoff\n",
    "namely `average`, `average_plus_std` and `upper_bound`, which work as follows:\n",
    "    - `average` means all clusters will pad ro prune nodes so that they adjust to\n",
    "the average number of nodes across all clusters;\n",
    "    - `average_plus_std` means all clusters will adjust to the average number of nodes across all clusters\n",
    "plus one standard deviation;\n",
    "    - `upper_bound` means all clusters will pad to the number of nodes in the largest cluster.\n",
    "In practice, the gains obtained by using a statically compiled graph are larger than the extra computations due to padding, even when using the `upper_bound` case.\n",
    "\n",
    "- `method_max_edges`: Same as `method_max_nodes` but for the number of edges per cluster.\n",
    "\n",
    "- `config.inter_cluster_ratio`: When using COO representation and sampling multiple cluster per batch, this parameter represents the extra number of edges that connect nodes that are in different that we will use. When this is zero, we can think the adjacency matrix of the batch as a pure block-diagonal matrix. If this value is greater than zero, then the adjacency matrix will have some positive values off the diagonal blocks.\n",
    "\n",
    "- `node_edge_imbalance_ratio`: By default the METIS clustering algorithm will find clusters that have similar number of nodes, though they can have very different number of edges. Setting this parameter we can tell METIS to find a trade-off between balancing number of nodes and edges. In theory this could reduce the amount of padding when using `upper_bound` method to set number of nodes and edges, but in practice we have observed but it doesn't have much effect on throughput for the considered datasets.\n",
    "\n",
    "We encourage you playing with different number of clusters and clusters per batch. The idea is to keep the number of nodes per batch large enough to minimise the number of lost edges, which affects accuracy, while fitting in memory, so we can benefit from the high bandwidth offered by a compiled computational graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "109740ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-12T00:03:41.923010Z",
     "iopub.status.busy": "2022-08-12T00:03:41.922811Z",
     "iopub.status.idle": "2022-08-12T00:03:56.880949Z",
     "shell.execute_reply": "2022-08-12T00:03:56.880454Z",
     "shell.execute_reply.started": "2022-08-12T00:03:41.922992Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-12 00:03:41 INFO     Unable to find full clustering cache.\n",
      "2022-08-12 00:03:41 INFO     Clustering graph with name ogbn-arxiv-training...\n",
      "2022-08-12 00:03:41 INFO     Nodes to edges balance ratio is set to None. This will mean metis will cluster attempting to balance the number of nodes in each cluster.\n",
      "2022-08-12 00:03:56 INFO     Clustering completed in 14.154 seconds.\n",
      "2022-08-12 00:03:56 INFO     Saving clusters in /notebooks/get-started/graph_datasets/clusters-ogbn-arxiv-training-SPARSE_TUPLE-UPPER_BOUND-UPPER_BOUND-0.0-None-50-num_clusters-1500.npy...\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n",
      "2022-08-12 00:03:56 INFO     Number of clusters (1500) provided, inferred max nodes per batch 3101 given the dataset size (90941 nodes) and clusters per batch (50).\n",
      "2022-08-12 00:03:56 INFO     Saving max_nodes_per_batch in /notebooks/get-started/graph_datasets/max_nodes_per_batch-ogbn-arxiv-training-SPARSE_TUPLE-UPPER_BOUND-UPPER_BOUND-0.0-None-50-num_clusters-1500.npy...\n",
      "2022-08-12 00:03:56 INFO     Counting the number of edges per cluster...\n",
      "100%|██████████| 1500/1500 [00:00<00:00, 2614.78it/s]\n",
      "2022-08-12 00:03:56 INFO     Inferred max num edges per batch 44277, given number of clusters (1500) and clusters per batch (50). This includes room for inter-cluster and self-loop edges.\n",
      "2022-08-12 00:03:56 INFO     Saving max_edges_per_batch in /notebooks/get-started/graph_datasets/max_edges_per_batch-ogbn-arxiv-training-SPARSE_TUPLE-UPPER_BOUND-UPPER_BOUND-0.0-None-50-num_clusters-1500.npy...\n"
     ]
    }
   ],
   "source": [
    "training_clusters = ClusterGraph(\n",
    "        adjacency=dataset.adjacency_train,\n",
    "        num_clusters=config.training.num_clusters,\n",
    "        visible_nodes=dataset.dataset_splits[\"train\"],\n",
    "        max_nodes_per_batch=config.training.max_nodes_per_batch,\n",
    "        clusters_per_batch=config.training.clusters_per_batch,\n",
    "        dataset_name=config.dataset_name + \"-training\",\n",
    "        cache_dir=config.data_path,\n",
    "        regenerate_cluster_cache=config.regenerate_clustering_cache,\n",
    "        save_clustering_cache=config.save_clustering_cache,\n",
    "        directed_graph=(dataset.graph_type == GraphType.DIRECTED),\n",
    "        adjacency_form=adjacency_form_training,\n",
    "        inter_cluster_ratio=config.inter_cluster_ratio,\n",
    "        method_max_nodes=method_max_nodes,\n",
    "        method_max_edges=method_max_edges,\n",
    "        node_edge_imbalance_ratio=config.cluster_node_edge_imbalance_ratio\n",
    "    )\n",
    "training_clusters.cluster_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad77d21b",
   "metadata": {},
   "source": [
    "We can compute some statistics on the impact of clustering on the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef8deae0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-12T00:03:56.881847Z",
     "iopub.status.busy": "2022-08-12T00:03:56.881684Z",
     "iopub.status.idle": "2022-08-12T00:04:03.706541Z",
     "shell.execute_reply": "2022-08-12T00:04:03.705758Z",
     "shell.execute_reply.started": "2022-08-12T00:03:56.881830Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-12 00:03:56 INFO     Evaluating statistics for the full graph...\n",
      "2022-08-12 00:03:58 INFO     Evaluating statistics for the clusters...\n",
      "2022-08-12 00:03:59 INFO     Evaluating statistics for the combined clusters (batches)...\n",
      "2022-08-12 00:04:03 INFO     Clustering statistics:\n",
      "Full graph:\n",
      "\t- Num nodes: 87599\n",
      "\t- Num edges: 369033\n",
      "\t- Sparsity ratio: 1.0000\n",
      "Clusters (sample size 500):\n",
      "\t- Num nodes: min 31.0000, mean 60.6200, max 62.0000, std 2.0678\n",
      "\t- Num edges: min 20.0000, mean 250.6320, max 960.0000, std 140.6261\n",
      "\t- Sparsity ratio: min 0.6743, mean 0.9327, max 0.9828, std 0.0382\n",
      "\t- Percentage of remaining edges: 50.9369 %\n",
      "Combined clusters (batches) (sample size 100):\n",
      "\t- Num nodes: min 2997.0000, mean 3031.3000, max 3066.0000, std 12.0768\n",
      "\t- Num edges: min 9978.0000, mean 12924.6000, max 16864.0000, std 1204.4316\n",
      "\t- Sparsity ratio: min 0.9982, mean 0.9986, max 0.9989, std 0.0001\n",
      "\t- Percentage of remaining edges: 52.5343 %\n",
      "2022-08-12 00:04:03 INFO     Weights & Biases not enabled. To see plots enable wandb in the config or on the command line.\n"
     ]
    }
   ],
   "source": [
    "clustering_statistics = ClusteringStatistics(\n",
    "    training_clusters.adjacency,\n",
    "    training_clusters.clusters,\n",
    "    num_clusters_per_batch=config.training.clusters_per_batch)\n",
    "clustering_statistics.get_statistics(wandb=config.wandb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978cd82c",
   "metadata": {},
   "source": [
    "Count the number of nodes that will be processed per epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e5de389",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-12T00:04:03.707741Z",
     "iopub.status.busy": "2022-08-12T00:04:03.707557Z",
     "iopub.status.idle": "2022-08-12T00:04:03.710765Z",
     "shell.execute_reply": "2022-08-12T00:04:03.710196Z",
     "shell.execute_reply.started": "2022-08-12T00:04:03.707723Z"
    }
   },
   "outputs": [],
   "source": [
    "num_real_nodes_per_epoch = len(dataset.dataset_splits[\"train\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57740ffe",
   "metadata": {},
   "source": [
    "### Build training dataset generator\n",
    "\n",
    "Create a efficient dataset generator for training using the TensorFlow `tf.data.Dataset` API. This allows preprocessing the data with multiple threads, increasing the speed at which the host can feed data to the Graphcore IPU. This is important, as the Graphcore IPU is so fast for GNN, that the host is usually the bottleneck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5b378ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-12T00:04:03.711605Z",
     "iopub.status.busy": "2022-08-12T00:04:03.711436Z",
     "iopub.status.idle": "2022-08-12T00:04:04.432979Z",
     "shell.execute_reply": "2022-08-12T00:04:04.432272Z",
     "shell.execute_reply.started": "2022-08-12T00:04:03.711589Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-12 00:04:04 INFO     Created batch generator for training: <PrefetchDataset shapes: ({adjacency_batch: ((1, 44277, 2), (1, 44277)), features_batch: (1, 3101, 256)}, (1, 3101, 1)), types: ({adjacency_batch: (tf.int32, tf.bool), features_batch: tf.float16}, tf.int32)>\n"
     ]
    }
   ],
   "source": [
    "data_generator_training = tf_dataset_generator(\n",
    "    adjacency=dataset.adjacency_train,\n",
    "    clusters=training_clusters.clusters,\n",
    "    features=dataset.features_train,\n",
    "    labels=dataset.labels,\n",
    "    mask=dataset.mask_train,\n",
    "    num_clusters=training_clusters.num_clusters,\n",
    "    clusters_per_batch=training_clusters.clusters_per_batch,\n",
    "    max_nodes_per_batch=training_clusters.max_nodes_per_batch,\n",
    "    max_edges_per_batch=training_clusters.max_edges_per_batch,\n",
    "    adjacency_dtype=adjacency_dtype_training,\n",
    "    adjacency_form=adjacency_form_training,\n",
    "    micro_batch_size=config.training.micro_batch_size,\n",
    "    seed=config.seed,\n",
    "    prefetch_depth=config.training.dataset_prefetch_depth,\n",
    "    distributed_worker_count=popdist.getNumInstances(),\n",
    "    distributed_worker_index=popdist.getInstanceIndex()\n",
    ")\n",
    "logging.info(\n",
    "    f\"Created batch generator for training: {data_generator_training}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d4e89a",
   "metadata": {},
   "source": [
    "As mentioned above, the Graphcore IPU is so fast that the dataset generator is usually the bottleneck, especially when we use distributed training with data parallelism, in which multiple replicas of the model run in different Graphcore IPU devices of a Graphcore POD.\n",
    "\n",
    "In order to be able to use the high throughput provided by a Graphcore IPU-POD16, we offer the `poprun` tool, that allows to launch multiple instances in the host, each one feeding data to one of the replicas. This is really easy to do from the command line, as explained in the README.md of this repo.\n",
    "\n",
    "The next cell gives some feedback about this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ca81a10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-12T00:04:04.434052Z",
     "iopub.status.busy": "2022-08-12T00:04:04.433875Z",
     "iopub.status.idle": "2022-08-12T00:04:04.436929Z",
     "shell.execute_reply": "2022-08-12T00:04:04.436375Z",
     "shell.execute_reply.started": "2022-08-12T00:04:04.434035Z"
    }
   },
   "outputs": [],
   "source": [
    "if config.training.replicas > 1:\n",
    "    logging.warning(f\"Increasing the number of model replicas will scale up the throughput if \"\n",
    "                    f\"the data generator in the host side is fast enough to feed data to all \"\n",
    "                    f\"the replicas. This is easily achieved with `poprun`. See README.md from \"\n",
    "                    f\"this repo for more information on how to scale the host throughput by \"\n",
    "                    f\"running multiple instances in the host, feeding one replica each.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b3a1d1",
   "metadata": {},
   "source": [
    "Create a batch config object that calculates the number of steps, micro-batches, etc. This is useful for distributed training, so we don't have to keep the numbers in mind when allocating data to the different replicas and/or pipeline stages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e696877",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-12T00:04:04.437836Z",
     "iopub.status.busy": "2022-08-12T00:04:04.437660Z",
     "iopub.status.idle": "2022-08-12T00:04:04.442977Z",
     "shell.execute_reply": "2022-08-12T00:04:04.442288Z",
     "shell.execute_reply.started": "2022-08-12T00:04:04.437819Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-12 00:04:04 INFO     Training batch config:\n",
      "\tMicro batch size: 1\n",
      "\tGradient accumulation count: 1\n",
      "\tGlobal batch size: 1\n",
      "\tNumber of replicas: 1\n",
      "\tSteps per execution: 30\n",
      "\tSteps per epoch: 30\n",
      "\tMax nodes per batch: 3101\n",
      "\tClusters per batch: 50\n",
      "\tNumber of nodes processed per execution: 93030\n",
      "\tNumber of clusters processed per execution: 1500\n",
      "\tNumber of actual epochs: 200\n",
      "\tNumber of corrected epochs (to account allow for multiple epochs in a single execution): 200\n",
      "\t\n"
     ]
    }
   ],
   "source": [
    "num_real_nodes_per_epoch = len(dataset.dataset_splits[\"train\"])\n",
    "batch_config_training = BatchConfig(\n",
    "    micro_batch_size=config.training.micro_batch_size,\n",
    "    num_clusters=training_clusters.num_clusters,\n",
    "    clusters_per_batch=training_clusters.clusters_per_batch,\n",
    "    max_nodes_per_batch=training_clusters.max_nodes_per_batch,\n",
    "    executions_per_epoch=config.training.executions_per_epoch,\n",
    "    gradient_accumulation_steps_per_replica=config.training.gradient_accumulation_steps_per_replica,\n",
    "    num_replicas=config.training.replicas,\n",
    "    epochs_per_execution=config.training.epochs_per_execution,\n",
    "    num_real_nodes_per_epoch=num_real_nodes_per_epoch,\n",
    "    num_epochs=config.training.epochs)\n",
    "logging.info(f\"Training batch config:\\n{batch_config_training}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed6cac8",
   "metadata": {},
   "source": [
    "### Training strategy\n",
    "\n",
    "We are ready to create the model. In order to compile the model for different hardware, we leverage TensorFlow's strategy scope, so that we can define the same Keras model to run on a POD of IPUs or on a CPU, and everything is handled under the hood, transparently for the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e2c3751c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-12T00:04:04.443840Z",
     "iopub.status.busy": "2022-08-12T00:04:04.443671Z",
     "iopub.status.idle": "2022-08-12T00:04:04.488755Z",
     "shell.execute_reply": "2022-08-12T00:04:04.487926Z",
     "shell.execute_reply.started": "2022-08-12T00:04:04.443824Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate the number of pipeline stages and the number of required IPUs per replica.\n",
    "num_pipeline_stages_training = len(\n",
    "    config.training.ipu_config.pipeline_device_mapping)\n",
    "num_ipus_per_replica_training = max(\n",
    "    config.training.ipu_config.pipeline_device_mapping) + 1\n",
    "\n",
    "# Create a strategy scope for training\n",
    "strategy_training_scope = create_ipu_strategy(\n",
    "    num_ipus_per_replica=num_pipeline_stages_training,\n",
    "    num_replicas=config.training.replicas,\n",
    "    matmul_available_memory_proportion=config.training.ipu_config.matmul_available_memory_proportion_per_pipeline_stage[0],\n",
    "    matmul_partials_type=precision.matmul_partials_type,\n",
    "    compile_only=config.compile_only,\n",
    "    enable_recomputation=config.training.ipu_config.enable_recomputation,\n",
    "    fp_exceptions=config.fp_exceptions,\n",
    "    num_io_tiles=config.training.ipu_config.num_io_tiles\n",
    ").scope() if config.training.device == \"ipu\" else tf.device(\"/cpu:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0653c6a2",
   "metadata": {},
   "source": [
    "### Creating and compile model, and training loop\n",
    "\n",
    "Create, compile and train the model within the desired strategy scope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ea53aa1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-12T00:04:04.489979Z",
     "iopub.status.busy": "2022-08-12T00:04:04.489797Z",
     "iopub.status.idle": "2022-08-12T00:07:04.408533Z",
     "shell.execute_reply": "2022-08-12T00:07:04.407497Z",
     "shell.execute_reply.started": "2022-08-12T00:04:04.489960Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-12 00:04:05 INFO     Model: \"model\"\n",
      "2022-08-12 00:04:05 INFO     __________________________________________________________________________________________________\n",
      "2022-08-12 00:04:05 INFO     Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "2022-08-12 00:04:05 INFO     ==================================================================================================\n",
      "2022-08-12 00:04:05 INFO     adjacency_edges (InputLayer)    [(1, 44277, 2)]      0                                            \n",
      "2022-08-12 00:04:05 INFO     __________________________________________________________________________________________________\n",
      "2022-08-12 00:04:05 INFO     adjacency_values (InputLayer)   [(1, 44277)]         0                                            \n",
      "2022-08-12 00:04:05 INFO     __________________________________________________________________________________________________\n",
      "2022-08-12 00:04:05 INFO     features (InputLayer)           [(1, 3101, 256)]     0                                            \n",
      "2022-08-12 00:04:05 INFO     __________________________________________________________________________________________________\n",
      "2022-08-12 00:04:05 INFO     tf.compat.v1.squeeze (TFOpLambd (44277, 2)           0           adjacency_edges[0][0]            \n",
      "2022-08-12 00:04:05 INFO     __________________________________________________________________________________________________\n",
      "2022-08-12 00:04:05 INFO     tf.compat.v1.squeeze_1 (TFOpLam (44277,)             0           adjacency_values[0][0]           \n",
      "2022-08-12 00:04:05 INFO     __________________________________________________________________________________________________\n",
      "2022-08-12 00:04:05 INFO     tf.compat.v1.squeeze_2 (TFOpLam (3101, 256)          0           features[0][0]                   \n",
      "2022-08-12 00:04:05 INFO     __________________________________________________________________________________________________\n",
      "2022-08-12 00:04:05 INFO     adjacency_processing (Adjacency ((44277, 2), (44277, 0           tf.compat.v1.squeeze[0][0]       \n",
      "2022-08-12 00:04:05 INFO                                                                      tf.compat.v1.squeeze_1[0][0]     \n",
      "2022-08-12 00:04:05 INFO     __________________________________________________________________________________________________\n",
      "2022-08-12 00:04:05 INFO     gcn_0 (GcnLayer)                (3101, 256)          66048       tf.compat.v1.squeeze_2[0][0]     \n",
      "2022-08-12 00:04:05 INFO                                                                      adjacency_processing[0][0]       \n",
      "2022-08-12 00:04:05 INFO                                                                      adjacency_processing[0][1]       \n",
      "2022-08-12 00:04:05 INFO                                                                      adjacency_processing[0][2]       \n",
      "2022-08-12 00:04:05 INFO     __________________________________________________________________________________________________\n",
      "2022-08-12 00:04:05 INFO     gcn_1 (GcnLayer)                (3101, 256)          131584      gcn_0[0][0]                      \n",
      "2022-08-12 00:04:05 INFO                                                                      adjacency_processing[0][0]       \n",
      "2022-08-12 00:04:05 INFO                                                                      adjacency_processing[0][1]       \n",
      "2022-08-12 00:04:05 INFO                                                                      adjacency_processing[0][2]       \n",
      "2022-08-12 00:04:05 INFO     __________________________________________________________________________________________________\n",
      "2022-08-12 00:04:05 INFO     gcn_2 (GcnLayer)                (3101, 256)          131584      gcn_1[0][0]                      \n",
      "2022-08-12 00:04:05 INFO                                                                      adjacency_processing[0][0]       \n",
      "2022-08-12 00:04:05 INFO                                                                      adjacency_processing[0][1]       \n",
      "2022-08-12 00:04:05 INFO                                                                      adjacency_processing[0][2]       \n",
      "2022-08-12 00:04:05 INFO     __________________________________________________________________________________________________\n",
      "2022-08-12 00:04:05 INFO     gcn_3 (GcnLayer)                (3101, 256)          131584      gcn_2[0][0]                      \n",
      "2022-08-12 00:04:05 INFO                                                                      adjacency_processing[0][0]       \n",
      "2022-08-12 00:04:05 INFO                                                                      adjacency_processing[0][1]       \n",
      "2022-08-12 00:04:05 INFO                                                                      adjacency_processing[0][2]       \n",
      "2022-08-12 00:04:05 INFO     __________________________________________________________________________________________________\n",
      "2022-08-12 00:04:05 INFO     output (GcnLayer)               (3101, 40)           20480       gcn_3[0][0]                      \n",
      "2022-08-12 00:04:05 INFO                                                                      adjacency_processing[0][0]       \n",
      "2022-08-12 00:04:05 INFO                                                                      adjacency_processing[0][1]       \n",
      "2022-08-12 00:04:05 INFO                                                                      adjacency_processing[0][2]       \n",
      "2022-08-12 00:04:05 INFO     ==================================================================================================\n",
      "2022-08-12 00:04:05 INFO     Total params: 481,280\n",
      "2022-08-12 00:04:05 INFO     Trainable params: 481,280\n",
      "2022-08-12 00:04:05 INFO     Non-trainable params: 0\n",
      "2022-08-12 00:04:05 INFO     __________________________________________________________________________________________________\n",
      "2022-08-12 00:04:05 INFO     Using loss and accuracy for multi class classification task.\n",
      "2022-08-12 00:04:05 INFO     Creating callback to report batch statistics.\n",
      "2022-08-12 00:04:05 INFO     Creating callbacks to read outfeed queues: [<tensorflow.python.ipu.ipu_outfeed_queue.IPUOutfeedQueue object at 0x7f68c0dd38b0>]\n",
      "2022-08-12 00:04:05 INFO     Creating callback for logging to terminal with a period of 1 log every 1 executions.\n",
      "2022-08-12 00:04:05 INFO     Logging with a period of 1 log every 1 executions.\n",
      "2022-08-12 00:04:05 INFO     Logging with a period of 1 log every 1 executions.\n",
      "2022-08-12 00:04:05 INFO     Creating callback for creating checkpoints. Checkpoints will be saved at a period of 1 every 0 executions to path: /notebooks/get-started/checkpoints/Cluster-GCN-ogbn-arxiv-fp16-ipu-AdjacencyForm.SPARSE_TUPLE-20220812_000306\n",
      "2022-08-12 00:06:39 INFO     Epoch 1 - Batch 30: loss: 3.084, accuracy_epoch_avg: 0.234, f1_score_macro_epoch_avg: 0.045, f1_score_micro_epoch_avg: 0.234, throughput: 606.001, loss_instantaneous: 3.080\n",
      "2022-08-12 00:06:39 INFO     Epoch 2 - Batch 30: loss: 2.166, accuracy_epoch_avg: 0.407, f1_score_macro_epoch_avg: 0.113, f1_score_micro_epoch_avg: 0.407, throughput: 809627.864, loss_instantaneous: 2.165\n",
      "2022-08-12 00:06:39 INFO     Epoch 3 - Batch 30: loss: 1.848, accuracy_epoch_avg: 0.487, f1_score_macro_epoch_avg: 0.166, f1_score_micro_epoch_avg: 0.487, throughput: 801128.615, loss_instantaneous: 1.849\n",
      "2022-08-12 00:06:39 INFO     Epoch 4 - Batch 30: loss: 1.656, accuracy_epoch_avg: 0.542, f1_score_macro_epoch_avg: 0.228, f1_score_micro_epoch_avg: 0.542, throughput: 819817.212, loss_instantaneous: 1.656\n",
      "2022-08-12 00:06:39 INFO     Epoch 5 - Batch 30: loss: 1.531, accuracy_epoch_avg: 0.574, f1_score_macro_epoch_avg: 0.269, f1_score_micro_epoch_avg: 0.574, throughput: 848112.271, loss_instantaneous: 1.532\n",
      "2022-08-12 00:06:39 INFO     Epoch 6 - Batch 30: loss: 1.479, accuracy_epoch_avg: 0.586, f1_score_macro_epoch_avg: 0.291, f1_score_micro_epoch_avg: 0.586, throughput: 825862.542, loss_instantaneous: 1.478\n",
      "2022-08-12 00:06:39 INFO     Epoch 7 - Batch 30: loss: 1.422, accuracy_epoch_avg: 0.601, f1_score_macro_epoch_avg: 0.319, f1_score_micro_epoch_avg: 0.601, throughput: 841892.445, loss_instantaneous: 1.421\n",
      "2022-08-12 00:06:40 INFO     Epoch 8 - Batch 30: loss: 1.372, accuracy_epoch_avg: 0.609, f1_score_macro_epoch_avg: 0.335, f1_score_micro_epoch_avg: 0.609, throughput: 801413.272, loss_instantaneous: 1.372\n",
      "2022-08-12 00:06:40 INFO     Epoch 9 - Batch 30: loss: 1.368, accuracy_epoch_avg: 0.612, f1_score_macro_epoch_avg: 0.348, f1_score_micro_epoch_avg: 0.612, throughput: 801141.774, loss_instantaneous: 1.367\n",
      "2022-08-12 00:06:40 INFO     Epoch 10 - Batch 30: loss: 1.337, accuracy_epoch_avg: 0.619, f1_score_macro_epoch_avg: 0.360, f1_score_micro_epoch_avg: 0.619, throughput: 795735.576, loss_instantaneous: 1.335\n",
      "2022-08-12 00:06:40 INFO     Epoch 11 - Batch 30: loss: 1.301, accuracy_epoch_avg: 0.632, f1_score_macro_epoch_avg: 0.379, f1_score_micro_epoch_avg: 0.632, throughput: 822273.901, loss_instantaneous: 1.301\n",
      "2022-08-12 00:06:40 INFO     Epoch 12 - Batch 30: loss: 1.276, accuracy_epoch_avg: 0.637, f1_score_macro_epoch_avg: 0.392, f1_score_micro_epoch_avg: 0.637, throughput: 832930.101, loss_instantaneous: 1.278\n",
      "2022-08-12 00:06:40 INFO     Epoch 13 - Batch 30: loss: 1.271, accuracy_epoch_avg: 0.635, f1_score_macro_epoch_avg: 0.396, f1_score_micro_epoch_avg: 0.635, throughput: 793352.407, loss_instantaneous: 1.271\n",
      "2022-08-12 00:06:40 INFO     Epoch 14 - Batch 30: loss: 1.249, accuracy_epoch_avg: 0.643, f1_score_macro_epoch_avg: 0.413, f1_score_micro_epoch_avg: 0.643, throughput: 794250.281, loss_instantaneous: 1.249\n",
      "2022-08-12 00:06:41 INFO     Epoch 15 - Batch 30: loss: 1.240, accuracy_epoch_avg: 0.644, f1_score_macro_epoch_avg: 0.412, f1_score_micro_epoch_avg: 0.644, throughput: 790457.893, loss_instantaneous: 1.242\n",
      "2022-08-12 00:06:41 INFO     Epoch 16 - Batch 30: loss: 1.216, accuracy_epoch_avg: 0.654, f1_score_macro_epoch_avg: 0.423, f1_score_micro_epoch_avg: 0.654, throughput: 783672.656, loss_instantaneous: 1.214\n",
      "2022-08-12 00:06:41 INFO     Epoch 17 - Batch 30: loss: 1.229, accuracy_epoch_avg: 0.648, f1_score_macro_epoch_avg: 0.426, f1_score_micro_epoch_avg: 0.648, throughput: 805049.251, loss_instantaneous: 1.228\n",
      "2022-08-12 00:06:41 INFO     Epoch 18 - Batch 30: loss: 1.205, accuracy_epoch_avg: 0.654, f1_score_macro_epoch_avg: 0.431, f1_score_micro_epoch_avg: 0.654, throughput: 836298.775, loss_instantaneous: 1.204\n",
      "2022-08-12 00:06:41 INFO     Epoch 19 - Batch 30: loss: 1.186, accuracy_epoch_avg: 0.659, f1_score_macro_epoch_avg: 0.433, f1_score_micro_epoch_avg: 0.659, throughput: 819137.401, loss_instantaneous: 1.183\n",
      "2022-08-12 00:06:41 INFO     Epoch 20 - Batch 30: loss: 1.176, accuracy_epoch_avg: 0.662, f1_score_macro_epoch_avg: 0.442, f1_score_micro_epoch_avg: 0.662, throughput: 781888.737, loss_instantaneous: 1.177\n",
      "2022-08-12 00:06:41 INFO     Epoch 21 - Batch 30: loss: 1.173, accuracy_epoch_avg: 0.661, f1_score_macro_epoch_avg: 0.443, f1_score_micro_epoch_avg: 0.661, throughput: 817395.706, loss_instantaneous: 1.174\n",
      "2022-08-12 00:06:41 INFO     Epoch 22 - Batch 30: loss: 1.170, accuracy_epoch_avg: 0.662, f1_score_macro_epoch_avg: 0.445, f1_score_micro_epoch_avg: 0.662, throughput: 798389.498, loss_instantaneous: 1.169\n",
      "2022-08-12 00:06:42 INFO     Epoch 23 - Batch 30: loss: 1.154, accuracy_epoch_avg: 0.667, f1_score_macro_epoch_avg: 0.452, f1_score_micro_epoch_avg: 0.667, throughput: 820565.445, loss_instantaneous: 1.155\n",
      "2022-08-12 00:06:42 INFO     Epoch 24 - Batch 30: loss: 1.153, accuracy_epoch_avg: 0.666, f1_score_macro_epoch_avg: 0.452, f1_score_micro_epoch_avg: 0.666, throughput: 803638.242, loss_instantaneous: 1.152\n",
      "2022-08-12 00:06:42 INFO     Epoch 25 - Batch 30: loss: 1.139, accuracy_epoch_avg: 0.669, f1_score_macro_epoch_avg: 0.458, f1_score_micro_epoch_avg: 0.669, throughput: 792231.307, loss_instantaneous: 1.139\n",
      "2022-08-12 00:06:42 INFO     Epoch 26 - Batch 30: loss: 1.137, accuracy_epoch_avg: 0.669, f1_score_macro_epoch_avg: 0.455, f1_score_micro_epoch_avg: 0.669, throughput: 816516.526, loss_instantaneous: 1.136\n",
      "2022-08-12 00:06:42 INFO     Epoch 27 - Batch 30: loss: 1.130, accuracy_epoch_avg: 0.670, f1_score_macro_epoch_avg: 0.466, f1_score_micro_epoch_avg: 0.670, throughput: 807742.358, loss_instantaneous: 1.130\n",
      "2022-08-12 00:06:42 INFO     Epoch 28 - Batch 30: loss: 1.120, accuracy_epoch_avg: 0.674, f1_score_macro_epoch_avg: 0.463, f1_score_micro_epoch_avg: 0.674, throughput: 822833.979, loss_instantaneous: 1.119\n",
      "2022-08-12 00:06:42 INFO     Epoch 29 - Batch 30: loss: 1.121, accuracy_epoch_avg: 0.674, f1_score_macro_epoch_avg: 0.469, f1_score_micro_epoch_avg: 0.674, throughput: 795596.043, loss_instantaneous: 1.119\n",
      "2022-08-12 00:06:42 INFO     Epoch 30 - Batch 30: loss: 1.104, accuracy_epoch_avg: 0.676, f1_score_macro_epoch_avg: 0.473, f1_score_micro_epoch_avg: 0.676, throughput: 790296.194, loss_instantaneous: 1.104\n",
      "2022-08-12 00:06:43 INFO     Epoch 31 - Batch 30: loss: 1.099, accuracy_epoch_avg: 0.678, f1_score_macro_epoch_avg: 0.474, f1_score_micro_epoch_avg: 0.678, throughput: 820349.800, loss_instantaneous: 1.099\n",
      "2022-08-12 00:06:43 INFO     Epoch 32 - Batch 30: loss: 1.095, accuracy_epoch_avg: 0.678, f1_score_macro_epoch_avg: 0.476, f1_score_micro_epoch_avg: 0.678, throughput: 815992.315, loss_instantaneous: 1.094\n",
      "2022-08-12 00:06:43 INFO     Epoch 33 - Batch 30: loss: 1.083, accuracy_epoch_avg: 0.685, f1_score_macro_epoch_avg: 0.482, f1_score_micro_epoch_avg: 0.685, throughput: 792765.689, loss_instantaneous: 1.083\n",
      "2022-08-12 00:06:43 INFO     Epoch 34 - Batch 30: loss: 1.095, accuracy_epoch_avg: 0.678, f1_score_macro_epoch_avg: 0.477, f1_score_micro_epoch_avg: 0.678, throughput: 788352.991, loss_instantaneous: 1.095\n",
      "2022-08-12 00:06:43 INFO     Epoch 35 - Batch 30: loss: 1.083, accuracy_epoch_avg: 0.681, f1_score_macro_epoch_avg: 0.480, f1_score_micro_epoch_avg: 0.681, throughput: 819725.931, loss_instantaneous: 1.082\n",
      "2022-08-12 00:06:43 INFO     Epoch 36 - Batch 30: loss: 1.085, accuracy_epoch_avg: 0.680, f1_score_macro_epoch_avg: 0.487, f1_score_micro_epoch_avg: 0.680, throughput: 801824.984, loss_instantaneous: 1.086\n",
      "2022-08-12 00:06:43 INFO     Epoch 37 - Batch 30: loss: 1.076, accuracy_epoch_avg: 0.684, f1_score_macro_epoch_avg: 0.475, f1_score_micro_epoch_avg: 0.684, throughput: 813805.425, loss_instantaneous: 1.077\n",
      "2022-08-12 00:06:43 INFO     Epoch 38 - Batch 30: loss: 1.080, accuracy_epoch_avg: 0.682, f1_score_macro_epoch_avg: 0.486, f1_score_micro_epoch_avg: 0.682, throughput: 822974.551, loss_instantaneous: 1.081\n",
      "2022-08-12 00:06:44 INFO     Epoch 39 - Batch 30: loss: 1.067, accuracy_epoch_avg: 0.684, f1_score_macro_epoch_avg: 0.488, f1_score_micro_epoch_avg: 0.684, throughput: 810026.201, loss_instantaneous: 1.068\n",
      "2022-08-12 00:06:44 INFO     Epoch 40 - Batch 30: loss: 1.067, accuracy_epoch_avg: 0.685, f1_score_macro_epoch_avg: 0.485, f1_score_micro_epoch_avg: 0.685, throughput: 789862.655, loss_instantaneous: 1.067\n",
      "2022-08-12 00:06:44 INFO     Epoch 41 - Batch 30: loss: 1.053, accuracy_epoch_avg: 0.688, f1_score_macro_epoch_avg: 0.489, f1_score_micro_epoch_avg: 0.688, throughput: 845138.243, loss_instantaneous: 1.053\n",
      "2022-08-12 00:06:44 INFO     Epoch 42 - Batch 30: loss: 1.058, accuracy_epoch_avg: 0.688, f1_score_macro_epoch_avg: 0.496, f1_score_micro_epoch_avg: 0.688, throughput: 841739.889, loss_instantaneous: 1.055\n",
      "2022-08-12 00:06:44 INFO     Epoch 43 - Batch 30: loss: 1.049, accuracy_epoch_avg: 0.690, f1_score_macro_epoch_avg: 0.496, f1_score_micro_epoch_avg: 0.690, throughput: 797656.683, loss_instantaneous: 1.049\n",
      "2022-08-12 00:06:44 INFO     Epoch 44 - Batch 30: loss: 1.040, accuracy_epoch_avg: 0.693, f1_score_macro_epoch_avg: 0.501, f1_score_micro_epoch_avg: 0.693, throughput: 789284.279, loss_instantaneous: 1.040\n",
      "2022-08-12 00:06:44 INFO     Epoch 45 - Batch 30: loss: 1.046, accuracy_epoch_avg: 0.690, f1_score_macro_epoch_avg: 0.502, f1_score_micro_epoch_avg: 0.690, throughput: 815536.952, loss_instantaneous: 1.046\n",
      "2022-08-12 00:06:44 INFO     Epoch 46 - Batch 30: loss: 1.040, accuracy_epoch_avg: 0.690, f1_score_macro_epoch_avg: 0.502, f1_score_micro_epoch_avg: 0.690, throughput: 833150.633, loss_instantaneous: 1.040\n",
      "2022-08-12 00:06:45 INFO     Epoch 47 - Batch 30: loss: 1.035, accuracy_epoch_avg: 0.692, f1_score_macro_epoch_avg: 0.500, f1_score_micro_epoch_avg: 0.692, throughput: 829653.722, loss_instantaneous: 1.034\n",
      "2022-08-12 00:06:45 INFO     Epoch 48 - Batch 30: loss: 1.037, accuracy_epoch_avg: 0.692, f1_score_macro_epoch_avg: 0.502, f1_score_micro_epoch_avg: 0.692, throughput: 824099.123, loss_instantaneous: 1.036\n",
      "2022-08-12 00:06:45 INFO     Epoch 49 - Batch 30: loss: 1.023, accuracy_epoch_avg: 0.694, f1_score_macro_epoch_avg: 0.507, f1_score_micro_epoch_avg: 0.694, throughput: 838372.358, loss_instantaneous: 1.023\n",
      "2022-08-12 00:06:45 INFO     Epoch 50 - Batch 30: loss: 1.026, accuracy_epoch_avg: 0.693, f1_score_macro_epoch_avg: 0.506, f1_score_micro_epoch_avg: 0.693, throughput: 815722.788, loss_instantaneous: 1.027\n",
      "2022-08-12 00:06:45 INFO     Epoch 51 - Batch 30: loss: 1.026, accuracy_epoch_avg: 0.693, f1_score_macro_epoch_avg: 0.504, f1_score_micro_epoch_avg: 0.693, throughput: 831696.215, loss_instantaneous: 1.026\n",
      "2022-08-12 00:06:45 INFO     Epoch 52 - Batch 30: loss: 1.022, accuracy_epoch_avg: 0.696, f1_score_macro_epoch_avg: 0.512, f1_score_micro_epoch_avg: 0.696, throughput: 836237.838, loss_instantaneous: 1.021\n",
      "2022-08-12 00:06:45 INFO     Epoch 53 - Batch 30: loss: 1.018, accuracy_epoch_avg: 0.694, f1_score_macro_epoch_avg: 0.508, f1_score_micro_epoch_avg: 0.694, throughput: 812595.356, loss_instantaneous: 1.018\n",
      "2022-08-12 00:06:45 INFO     Epoch 54 - Batch 30: loss: 1.017, accuracy_epoch_avg: 0.693, f1_score_macro_epoch_avg: 0.502, f1_score_micro_epoch_avg: 0.694, throughput: 802803.258, loss_instantaneous: 1.016\n",
      "2022-08-12 00:06:45 INFO     Epoch 55 - Batch 30: loss: 1.014, accuracy_epoch_avg: 0.698, f1_score_macro_epoch_avg: 0.517, f1_score_micro_epoch_avg: 0.698, throughput: 833668.630, loss_instantaneous: 1.013\n",
      "2022-08-12 00:06:46 INFO     Epoch 56 - Batch 30: loss: 1.011, accuracy_epoch_avg: 0.697, f1_score_macro_epoch_avg: 0.517, f1_score_micro_epoch_avg: 0.697, throughput: 815254.098, loss_instantaneous: 1.012\n",
      "2022-08-12 00:06:46 INFO     Epoch 57 - Batch 30: loss: 1.000, accuracy_epoch_avg: 0.698, f1_score_macro_epoch_avg: 0.515, f1_score_micro_epoch_avg: 0.699, throughput: 823754.647, loss_instantaneous: 1.001\n",
      "2022-08-12 00:06:46 INFO     Epoch 58 - Batch 30: loss: 1.010, accuracy_epoch_avg: 0.696, f1_score_macro_epoch_avg: 0.512, f1_score_micro_epoch_avg: 0.696, throughput: 815905.296, loss_instantaneous: 1.010\n",
      "2022-08-12 00:06:46 INFO     Epoch 59 - Batch 30: loss: 1.005, accuracy_epoch_avg: 0.697, f1_score_macro_epoch_avg: 0.515, f1_score_micro_epoch_avg: 0.697, throughput: 825972.679, loss_instantaneous: 1.005\n",
      "2022-08-12 00:06:46 INFO     Epoch 60 - Batch 30: loss: 1.006, accuracy_epoch_avg: 0.699, f1_score_macro_epoch_avg: 0.516, f1_score_micro_epoch_avg: 0.699, throughput: 804106.924, loss_instantaneous: 1.004\n",
      "2022-08-12 00:06:46 INFO     Epoch 61 - Batch 30: loss: 1.002, accuracy_epoch_avg: 0.699, f1_score_macro_epoch_avg: 0.514, f1_score_micro_epoch_avg: 0.699, throughput: 785899.788, loss_instantaneous: 1.002\n",
      "2022-08-12 00:06:46 INFO     Epoch 62 - Batch 30: loss: 0.998, accuracy_epoch_avg: 0.699, f1_score_macro_epoch_avg: 0.523, f1_score_micro_epoch_avg: 0.699, throughput: 800556.622, loss_instantaneous: 0.998\n",
      "2022-08-12 00:06:47 INFO     Epoch 63 - Batch 30: loss: 0.999, accuracy_epoch_avg: 0.699, f1_score_macro_epoch_avg: 0.522, f1_score_micro_epoch_avg: 0.699, throughput: 776054.060, loss_instantaneous: 0.998\n",
      "2022-08-12 00:06:47 INFO     Epoch 64 - Batch 30: loss: 0.991, accuracy_epoch_avg: 0.701, f1_score_macro_epoch_avg: 0.523, f1_score_micro_epoch_avg: 0.701, throughput: 789809.895, loss_instantaneous: 0.991\n",
      "2022-08-12 00:06:47 INFO     Epoch 65 - Batch 30: loss: 0.988, accuracy_epoch_avg: 0.702, f1_score_macro_epoch_avg: 0.523, f1_score_micro_epoch_avg: 0.702, throughput: 808830.689, loss_instantaneous: 0.989\n",
      "2022-08-12 00:06:47 INFO     Epoch 66 - Batch 30: loss: 0.993, accuracy_epoch_avg: 0.700, f1_score_macro_epoch_avg: 0.523, f1_score_micro_epoch_avg: 0.700, throughput: 821679.978, loss_instantaneous: 0.993\n",
      "2022-08-12 00:06:47 INFO     Epoch 67 - Batch 30: loss: 0.983, accuracy_epoch_avg: 0.704, f1_score_macro_epoch_avg: 0.526, f1_score_micro_epoch_avg: 0.704, throughput: 826357.513, loss_instantaneous: 0.983\n",
      "2022-08-12 00:06:47 INFO     Epoch 68 - Batch 30: loss: 0.992, accuracy_epoch_avg: 0.700, f1_score_macro_epoch_avg: 0.521, f1_score_micro_epoch_avg: 0.700, throughput: 797976.410, loss_instantaneous: 0.992\n",
      "2022-08-12 00:06:47 INFO     Epoch 69 - Batch 30: loss: 0.987, accuracy_epoch_avg: 0.701, f1_score_macro_epoch_avg: 0.516, f1_score_micro_epoch_avg: 0.701, throughput: 827798.571, loss_instantaneous: 0.987\n",
      "2022-08-12 00:06:47 INFO     Epoch 70 - Batch 30: loss: 0.972, accuracy_epoch_avg: 0.706, f1_score_macro_epoch_avg: 0.533, f1_score_micro_epoch_avg: 0.706, throughput: 809690.026, loss_instantaneous: 0.972\n",
      "2022-08-12 00:06:48 INFO     Epoch 71 - Batch 30: loss: 0.987, accuracy_epoch_avg: 0.701, f1_score_macro_epoch_avg: 0.526, f1_score_micro_epoch_avg: 0.701, throughput: 821789.001, loss_instantaneous: 0.987\n",
      "2022-08-12 00:06:48 INFO     Epoch 72 - Batch 30: loss: 0.984, accuracy_epoch_avg: 0.700, f1_score_macro_epoch_avg: 0.524, f1_score_micro_epoch_avg: 0.700, throughput: 836286.229, loss_instantaneous: 0.983\n",
      "2022-08-12 00:06:48 INFO     Epoch 73 - Batch 30: loss: 0.979, accuracy_epoch_avg: 0.702, f1_score_macro_epoch_avg: 0.525, f1_score_micro_epoch_avg: 0.702, throughput: 827051.118, loss_instantaneous: 0.979\n",
      "2022-08-12 00:06:48 INFO     Epoch 74 - Batch 30: loss: 0.976, accuracy_epoch_avg: 0.704, f1_score_macro_epoch_avg: 0.529, f1_score_micro_epoch_avg: 0.704, throughput: 826910.902, loss_instantaneous: 0.976\n",
      "2022-08-12 00:06:48 INFO     Epoch 75 - Batch 30: loss: 0.976, accuracy_epoch_avg: 0.704, f1_score_macro_epoch_avg: 0.528, f1_score_micro_epoch_avg: 0.704, throughput: 835119.236, loss_instantaneous: 0.977\n",
      "2022-08-12 00:06:48 INFO     Epoch 76 - Batch 30: loss: 0.970, accuracy_epoch_avg: 0.706, f1_score_macro_epoch_avg: 0.530, f1_score_micro_epoch_avg: 0.706, throughput: 856971.144, loss_instantaneous: 0.971\n",
      "2022-08-12 00:06:48 INFO     Epoch 77 - Batch 30: loss: 0.976, accuracy_epoch_avg: 0.704, f1_score_macro_epoch_avg: 0.527, f1_score_micro_epoch_avg: 0.704, throughput: 856767.922, loss_instantaneous: 0.976\n",
      "2022-08-12 00:06:48 INFO     Epoch 78 - Batch 30: loss: 0.962, accuracy_epoch_avg: 0.708, f1_score_macro_epoch_avg: 0.538, f1_score_micro_epoch_avg: 0.708, throughput: 795970.946, loss_instantaneous: 0.962\n",
      "2022-08-12 00:06:49 INFO     Epoch 79 - Batch 30: loss: 0.968, accuracy_epoch_avg: 0.704, f1_score_macro_epoch_avg: 0.534, f1_score_micro_epoch_avg: 0.704, throughput: 803639.897, loss_instantaneous: 0.968\n",
      "2022-08-12 00:06:49 INFO     Epoch 80 - Batch 30: loss: 0.972, accuracy_epoch_avg: 0.704, f1_score_macro_epoch_avg: 0.539, f1_score_micro_epoch_avg: 0.704, throughput: 834708.344, loss_instantaneous: 0.973\n",
      "2022-08-12 00:06:49 INFO     Epoch 81 - Batch 30: loss: 0.964, accuracy_epoch_avg: 0.706, f1_score_macro_epoch_avg: 0.533, f1_score_micro_epoch_avg: 0.706, throughput: 807974.848, loss_instantaneous: 0.965\n",
      "2022-08-12 00:06:49 INFO     Epoch 82 - Batch 30: loss: 0.962, accuracy_epoch_avg: 0.708, f1_score_macro_epoch_avg: 0.535, f1_score_micro_epoch_avg: 0.708, throughput: 821889.398, loss_instantaneous: 0.962\n",
      "2022-08-12 00:06:49 INFO     Epoch 83 - Batch 30: loss: 0.970, accuracy_epoch_avg: 0.705, f1_score_macro_epoch_avg: 0.532, f1_score_micro_epoch_avg: 0.705, throughput: 802459.848, loss_instantaneous: 0.969\n",
      "2022-08-12 00:06:49 INFO     Epoch 84 - Batch 30: loss: 0.965, accuracy_epoch_avg: 0.706, f1_score_macro_epoch_avg: 0.532, f1_score_micro_epoch_avg: 0.706, throughput: 820070.493, loss_instantaneous: 0.965\n",
      "2022-08-12 00:06:49 INFO     Epoch 85 - Batch 30: loss: 0.956, accuracy_epoch_avg: 0.708, f1_score_macro_epoch_avg: 0.536, f1_score_micro_epoch_avg: 0.708, throughput: 829232.328, loss_instantaneous: 0.957\n",
      "2022-08-12 00:06:49 INFO     Epoch 86 - Batch 30: loss: 0.958, accuracy_epoch_avg: 0.705, f1_score_macro_epoch_avg: 0.539, f1_score_micro_epoch_avg: 0.705, throughput: 786703.135, loss_instantaneous: 0.959\n",
      "2022-08-12 00:06:50 INFO     Epoch 87 - Batch 30: loss: 0.963, accuracy_epoch_avg: 0.707, f1_score_macro_epoch_avg: 0.539, f1_score_micro_epoch_avg: 0.707, throughput: 801831.575, loss_instantaneous: 0.964\n",
      "2022-08-12 00:06:50 INFO     Epoch 88 - Batch 30: loss: 0.953, accuracy_epoch_avg: 0.709, f1_score_macro_epoch_avg: 0.535, f1_score_micro_epoch_avg: 0.709, throughput: 815760.306, loss_instantaneous: 0.953\n",
      "2022-08-12 00:06:50 INFO     Epoch 89 - Batch 30: loss: 0.959, accuracy_epoch_avg: 0.707, f1_score_macro_epoch_avg: 0.540, f1_score_micro_epoch_avg: 0.707, throughput: 802662.887, loss_instantaneous: 0.959\n",
      "2022-08-12 00:06:50 INFO     Epoch 90 - Batch 30: loss: 0.958, accuracy_epoch_avg: 0.709, f1_score_macro_epoch_avg: 0.534, f1_score_micro_epoch_avg: 0.709, throughput: 789728.371, loss_instantaneous: 0.959\n",
      "2022-08-12 00:06:50 INFO     Epoch 91 - Batch 30: loss: 0.946, accuracy_epoch_avg: 0.709, f1_score_macro_epoch_avg: 0.537, f1_score_micro_epoch_avg: 0.709, throughput: 820845.090, loss_instantaneous: 0.945\n",
      "2022-08-12 00:06:50 INFO     Epoch 92 - Batch 30: loss: 0.955, accuracy_epoch_avg: 0.708, f1_score_macro_epoch_avg: 0.543, f1_score_micro_epoch_avg: 0.708, throughput: 820529.209, loss_instantaneous: 0.955\n",
      "2022-08-12 00:06:50 INFO     Epoch 93 - Batch 30: loss: 0.947, accuracy_epoch_avg: 0.710, f1_score_macro_epoch_avg: 0.540, f1_score_micro_epoch_avg: 0.710, throughput: 839745.408, loss_instantaneous: 0.947\n",
      "2022-08-12 00:06:50 INFO     Epoch 94 - Batch 30: loss: 0.952, accuracy_epoch_avg: 0.709, f1_score_macro_epoch_avg: 0.540, f1_score_micro_epoch_avg: 0.709, throughput: 684111.691, loss_instantaneous: 0.952\n",
      "2022-08-12 00:06:51 INFO     Epoch 95 - Batch 30: loss: 0.952, accuracy_epoch_avg: 0.710, f1_score_macro_epoch_avg: 0.546, f1_score_micro_epoch_avg: 0.710, throughput: 809809.336, loss_instantaneous: 0.952\n",
      "2022-08-12 00:06:51 INFO     Epoch 96 - Batch 30: loss: 0.951, accuracy_epoch_avg: 0.709, f1_score_macro_epoch_avg: 0.539, f1_score_micro_epoch_avg: 0.709, throughput: 806020.428, loss_instantaneous: 0.951\n",
      "2022-08-12 00:06:51 INFO     Epoch 97 - Batch 30: loss: 0.948, accuracy_epoch_avg: 0.709, f1_score_macro_epoch_avg: 0.544, f1_score_micro_epoch_avg: 0.709, throughput: 839035.768, loss_instantaneous: 0.949\n",
      "2022-08-12 00:06:51 INFO     Epoch 98 - Batch 30: loss: 0.947, accuracy_epoch_avg: 0.710, f1_score_macro_epoch_avg: 0.547, f1_score_micro_epoch_avg: 0.710, throughput: 793542.793, loss_instantaneous: 0.947\n",
      "2022-08-12 00:06:51 INFO     Epoch 99 - Batch 30: loss: 0.948, accuracy_epoch_avg: 0.711, f1_score_macro_epoch_avg: 0.539, f1_score_micro_epoch_avg: 0.711, throughput: 810800.463, loss_instantaneous: 0.947\n",
      "2022-08-12 00:06:51 INFO     Epoch 100 - Batch 30: loss: 0.950, accuracy_epoch_avg: 0.707, f1_score_macro_epoch_avg: 0.539, f1_score_micro_epoch_avg: 0.707, throughput: 841364.182, loss_instantaneous: 0.948\n",
      "2022-08-12 00:06:51 INFO     Epoch 101 - Batch 30: loss: 0.938, accuracy_epoch_avg: 0.713, f1_score_macro_epoch_avg: 0.543, f1_score_micro_epoch_avg: 0.713, throughput: 801694.837, loss_instantaneous: 0.938\n",
      "2022-08-12 00:06:51 INFO     Epoch 102 - Batch 30: loss: 0.940, accuracy_epoch_avg: 0.711, f1_score_macro_epoch_avg: 0.545, f1_score_micro_epoch_avg: 0.711, throughput: 832095.274, loss_instantaneous: 0.939\n",
      "2022-08-12 00:06:52 INFO     Epoch 103 - Batch 30: loss: 0.940, accuracy_epoch_avg: 0.711, f1_score_macro_epoch_avg: 0.550, f1_score_micro_epoch_avg: 0.711, throughput: 784583.447, loss_instantaneous: 0.940\n",
      "2022-08-12 00:06:52 INFO     Epoch 104 - Batch 30: loss: 0.945, accuracy_epoch_avg: 0.711, f1_score_macro_epoch_avg: 0.548, f1_score_micro_epoch_avg: 0.711, throughput: 770030.670, loss_instantaneous: 0.944\n",
      "2022-08-12 00:06:52 INFO     Epoch 105 - Batch 30: loss: 0.935, accuracy_epoch_avg: 0.711, f1_score_macro_epoch_avg: 0.542, f1_score_micro_epoch_avg: 0.711, throughput: 808276.112, loss_instantaneous: 0.935\n",
      "2022-08-12 00:06:52 INFO     Epoch 106 - Batch 30: loss: 0.939, accuracy_epoch_avg: 0.711, f1_score_macro_epoch_avg: 0.545, f1_score_micro_epoch_avg: 0.711, throughput: 802162.903, loss_instantaneous: 0.940\n",
      "2022-08-12 00:06:52 INFO     Epoch 107 - Batch 30: loss: 0.936, accuracy_epoch_avg: 0.713, f1_score_macro_epoch_avg: 0.553, f1_score_micro_epoch_avg: 0.713, throughput: 796115.483, loss_instantaneous: 0.936\n",
      "2022-08-12 00:06:52 INFO     Epoch 108 - Batch 30: loss: 0.941, accuracy_epoch_avg: 0.709, f1_score_macro_epoch_avg: 0.541, f1_score_micro_epoch_avg: 0.709, throughput: 811773.752, loss_instantaneous: 0.940\n",
      "2022-08-12 00:06:52 INFO     Epoch 109 - Batch 30: loss: 0.939, accuracy_epoch_avg: 0.709, f1_score_macro_epoch_avg: 0.544, f1_score_micro_epoch_avg: 0.709, throughput: 788918.837, loss_instantaneous: 0.941\n",
      "2022-08-12 00:06:52 INFO     Epoch 110 - Batch 30: loss: 0.934, accuracy_epoch_avg: 0.712, f1_score_macro_epoch_avg: 0.551, f1_score_micro_epoch_avg: 0.712, throughput: 824701.779, loss_instantaneous: 0.935\n",
      "2022-08-12 00:06:53 INFO     Epoch 111 - Batch 30: loss: 0.936, accuracy_epoch_avg: 0.714, f1_score_macro_epoch_avg: 0.543, f1_score_micro_epoch_avg: 0.714, throughput: 802453.247, loss_instantaneous: 0.936\n",
      "2022-08-12 00:06:53 INFO     Epoch 112 - Batch 30: loss: 0.936, accuracy_epoch_avg: 0.712, f1_score_macro_epoch_avg: 0.547, f1_score_micro_epoch_avg: 0.712, throughput: 822854.801, loss_instantaneous: 0.936\n",
      "2022-08-12 00:06:53 INFO     Epoch 113 - Batch 30: loss: 0.936, accuracy_epoch_avg: 0.710, f1_score_macro_epoch_avg: 0.550, f1_score_micro_epoch_avg: 0.710, throughput: 792675.502, loss_instantaneous: 0.936\n",
      "2022-08-12 00:06:53 INFO     Epoch 114 - Batch 30: loss: 0.935, accuracy_epoch_avg: 0.712, f1_score_macro_epoch_avg: 0.544, f1_score_micro_epoch_avg: 0.712, throughput: 824572.814, loss_instantaneous: 0.934\n",
      "2022-08-12 00:06:53 INFO     Epoch 115 - Batch 30: loss: 0.929, accuracy_epoch_avg: 0.714, f1_score_macro_epoch_avg: 0.548, f1_score_micro_epoch_avg: 0.714, throughput: 807207.640, loss_instantaneous: 0.929\n",
      "2022-08-12 00:06:53 INFO     Epoch 116 - Batch 30: loss: 0.933, accuracy_epoch_avg: 0.711, f1_score_macro_epoch_avg: 0.549, f1_score_micro_epoch_avg: 0.712, throughput: 776452.482, loss_instantaneous: 0.934\n",
      "2022-08-12 00:06:53 INFO     Epoch 117 - Batch 30: loss: 0.924, accuracy_epoch_avg: 0.716, f1_score_macro_epoch_avg: 0.546, f1_score_micro_epoch_avg: 0.716, throughput: 791103.747, loss_instantaneous: 0.925\n",
      "2022-08-12 00:06:53 INFO     Epoch 118 - Batch 30: loss: 0.931, accuracy_epoch_avg: 0.712, f1_score_macro_epoch_avg: 0.549, f1_score_micro_epoch_avg: 0.712, throughput: 680023.460, loss_instantaneous: 0.932\n",
      "2022-08-12 00:06:54 INFO     Epoch 119 - Batch 30: loss: 0.922, accuracy_epoch_avg: 0.714, f1_score_macro_epoch_avg: 0.555, f1_score_micro_epoch_avg: 0.714, throughput: 815864.353, loss_instantaneous: 0.923\n",
      "2022-08-12 00:06:54 INFO     Epoch 120 - Batch 30: loss: 0.927, accuracy_epoch_avg: 0.714, f1_score_macro_epoch_avg: 0.549, f1_score_micro_epoch_avg: 0.714, throughput: 841672.709, loss_instantaneous: 0.927\n",
      "2022-08-12 00:06:54 INFO     Epoch 121 - Batch 30: loss: 0.928, accuracy_epoch_avg: 0.714, f1_score_macro_epoch_avg: 0.549, f1_score_micro_epoch_avg: 0.714, throughput: 822754.169, loss_instantaneous: 0.927\n",
      "2022-08-12 00:06:54 INFO     Epoch 122 - Batch 30: loss: 0.929, accuracy_epoch_avg: 0.714, f1_score_macro_epoch_avg: 0.557, f1_score_micro_epoch_avg: 0.714, throughput: 762232.769, loss_instantaneous: 0.928\n",
      "2022-08-12 00:06:54 INFO     Epoch 123 - Batch 30: loss: 0.921, accuracy_epoch_avg: 0.716, f1_score_macro_epoch_avg: 0.554, f1_score_micro_epoch_avg: 0.716, throughput: 778022.346, loss_instantaneous: 0.922\n",
      "2022-08-12 00:06:54 INFO     Epoch 124 - Batch 30: loss: 0.924, accuracy_epoch_avg: 0.713, f1_score_macro_epoch_avg: 0.551, f1_score_micro_epoch_avg: 0.713, throughput: 764435.378, loss_instantaneous: 0.925\n",
      "2022-08-12 00:06:54 INFO     Epoch 125 - Batch 30: loss: 0.925, accuracy_epoch_avg: 0.712, f1_score_macro_epoch_avg: 0.553, f1_score_micro_epoch_avg: 0.712, throughput: 768070.810, loss_instantaneous: 0.925\n",
      "2022-08-12 00:06:54 INFO     Epoch 126 - Batch 30: loss: 0.927, accuracy_epoch_avg: 0.713, f1_score_macro_epoch_avg: 0.552, f1_score_micro_epoch_avg: 0.713, throughput: 725784.199, loss_instantaneous: 0.927\n",
      "2022-08-12 00:06:55 INFO     Epoch 127 - Batch 30: loss: 0.922, accuracy_epoch_avg: 0.713, f1_score_macro_epoch_avg: 0.553, f1_score_micro_epoch_avg: 0.713, throughput: 641715.020, loss_instantaneous: 0.923\n",
      "2022-08-12 00:06:55 INFO     Epoch 128 - Batch 30: loss: 0.917, accuracy_epoch_avg: 0.717, f1_score_macro_epoch_avg: 0.549, f1_score_micro_epoch_avg: 0.717, throughput: 770464.003, loss_instantaneous: 0.916\n",
      "2022-08-12 00:06:55 INFO     Epoch 129 - Batch 30: loss: 0.923, accuracy_epoch_avg: 0.714, f1_score_macro_epoch_avg: 0.554, f1_score_micro_epoch_avg: 0.714, throughput: 776281.018, loss_instantaneous: 0.924\n",
      "2022-08-12 00:06:55 INFO     Epoch 130 - Batch 30: loss: 0.923, accuracy_epoch_avg: 0.714, f1_score_macro_epoch_avg: 0.555, f1_score_micro_epoch_avg: 0.714, throughput: 827156.311, loss_instantaneous: 0.924\n",
      "2022-08-12 00:06:55 INFO     Epoch 131 - Batch 30: loss: 0.924, accuracy_epoch_avg: 0.714, f1_score_macro_epoch_avg: 0.549, f1_score_micro_epoch_avg: 0.714, throughput: 829699.589, loss_instantaneous: 0.924\n",
      "2022-08-12 00:06:55 INFO     Epoch 132 - Batch 30: loss: 0.922, accuracy_epoch_avg: 0.715, f1_score_macro_epoch_avg: 0.552, f1_score_micro_epoch_avg: 0.715, throughput: 791453.557, loss_instantaneous: 0.922\n",
      "2022-08-12 00:06:55 INFO     Epoch 133 - Batch 30: loss: 0.925, accuracy_epoch_avg: 0.713, f1_score_macro_epoch_avg: 0.556, f1_score_micro_epoch_avg: 0.714, throughput: 782242.989, loss_instantaneous: 0.925\n",
      "2022-08-12 00:06:56 INFO     Epoch 134 - Batch 30: loss: 0.917, accuracy_epoch_avg: 0.715, f1_score_macro_epoch_avg: 0.551, f1_score_micro_epoch_avg: 0.715, throughput: 822811.422, loss_instantaneous: 0.917\n",
      "2022-08-12 00:06:56 INFO     Epoch 135 - Batch 30: loss: 0.917, accuracy_epoch_avg: 0.716, f1_score_macro_epoch_avg: 0.557, f1_score_micro_epoch_avg: 0.716, throughput: 819459.095, loss_instantaneous: 0.917\n",
      "2022-08-12 00:06:56 INFO     Epoch 136 - Batch 30: loss: 0.917, accuracy_epoch_avg: 0.715, f1_score_macro_epoch_avg: 0.559, f1_score_micro_epoch_avg: 0.715, throughput: 831185.977, loss_instantaneous: 0.916\n",
      "2022-08-12 00:06:56 INFO     Epoch 137 - Batch 30: loss: 0.917, accuracy_epoch_avg: 0.716, f1_score_macro_epoch_avg: 0.550, f1_score_micro_epoch_avg: 0.716, throughput: 788395.998, loss_instantaneous: 0.917\n",
      "2022-08-12 00:06:56 INFO     Epoch 138 - Batch 30: loss: 0.914, accuracy_epoch_avg: 0.716, f1_score_macro_epoch_avg: 0.556, f1_score_micro_epoch_avg: 0.716, throughput: 811291.033, loss_instantaneous: 0.914\n",
      "2022-08-12 00:06:56 INFO     Epoch 139 - Batch 30: loss: 0.915, accuracy_epoch_avg: 0.716, f1_score_macro_epoch_avg: 0.554, f1_score_micro_epoch_avg: 0.716, throughput: 799990.366, loss_instantaneous: 0.914\n",
      "2022-08-12 00:06:56 INFO     Epoch 140 - Batch 30: loss: 0.915, accuracy_epoch_avg: 0.715, f1_score_macro_epoch_avg: 0.554, f1_score_micro_epoch_avg: 0.715, throughput: 797752.901, loss_instantaneous: 0.914\n",
      "2022-08-12 00:06:56 INFO     Epoch 141 - Batch 30: loss: 0.909, accuracy_epoch_avg: 0.717, f1_score_macro_epoch_avg: 0.559, f1_score_micro_epoch_avg: 0.717, throughput: 810179.253, loss_instantaneous: 0.909\n",
      "2022-08-12 00:06:57 INFO     Epoch 142 - Batch 30: loss: 0.909, accuracy_epoch_avg: 0.718, f1_score_macro_epoch_avg: 0.555, f1_score_micro_epoch_avg: 0.718, throughput: 818364.306, loss_instantaneous: 0.908\n",
      "2022-08-12 00:06:57 INFO     Epoch 143 - Batch 30: loss: 0.914, accuracy_epoch_avg: 0.714, f1_score_macro_epoch_avg: 0.554, f1_score_micro_epoch_avg: 0.714, throughput: 808458.653, loss_instantaneous: 0.913\n",
      "2022-08-12 00:06:57 INFO     Epoch 144 - Batch 30: loss: 0.914, accuracy_epoch_avg: 0.716, f1_score_macro_epoch_avg: 0.555, f1_score_micro_epoch_avg: 0.716, throughput: 793856.000, loss_instantaneous: 0.913\n",
      "2022-08-12 00:06:57 INFO     Epoch 145 - Batch 30: loss: 0.911, accuracy_epoch_avg: 0.718, f1_score_macro_epoch_avg: 0.558, f1_score_micro_epoch_avg: 0.718, throughput: 802577.037, loss_instantaneous: 0.911\n",
      "2022-08-12 00:06:57 INFO     Epoch 146 - Batch 30: loss: 0.911, accuracy_epoch_avg: 0.717, f1_score_macro_epoch_avg: 0.553, f1_score_micro_epoch_avg: 0.717, throughput: 828002.337, loss_instantaneous: 0.911\n",
      "2022-08-12 00:06:57 INFO     Epoch 147 - Batch 30: loss: 0.908, accuracy_epoch_avg: 0.718, f1_score_macro_epoch_avg: 0.557, f1_score_micro_epoch_avg: 0.718, throughput: 820663.817, loss_instantaneous: 0.908\n",
      "2022-08-12 00:06:57 INFO     Epoch 148 - Batch 30: loss: 0.925, accuracy_epoch_avg: 0.712, f1_score_macro_epoch_avg: 0.557, f1_score_micro_epoch_avg: 0.712, throughput: 805657.625, loss_instantaneous: 0.925\n",
      "2022-08-12 00:06:57 INFO     Epoch 149 - Batch 30: loss: 0.904, accuracy_epoch_avg: 0.719, f1_score_macro_epoch_avg: 0.556, f1_score_micro_epoch_avg: 0.719, throughput: 792306.914, loss_instantaneous: 0.903\n",
      "2022-08-12 00:06:58 INFO     Epoch 150 - Batch 30: loss: 0.910, accuracy_epoch_avg: 0.717, f1_score_macro_epoch_avg: 0.557, f1_score_micro_epoch_avg: 0.717, throughput: 806161.976, loss_instantaneous: 0.910\n",
      "2022-08-12 00:06:58 INFO     Epoch 151 - Batch 30: loss: 0.908, accuracy_epoch_avg: 0.718, f1_score_macro_epoch_avg: 0.561, f1_score_micro_epoch_avg: 0.718, throughput: 764438.373, loss_instantaneous: 0.910\n",
      "2022-08-12 00:06:58 INFO     Epoch 152 - Batch 30: loss: 0.902, accuracy_epoch_avg: 0.717, f1_score_macro_epoch_avg: 0.550, f1_score_micro_epoch_avg: 0.717, throughput: 800614.114, loss_instantaneous: 0.903\n",
      "2022-08-12 00:06:58 INFO     Epoch 153 - Batch 30: loss: 0.909, accuracy_epoch_avg: 0.716, f1_score_macro_epoch_avg: 0.552, f1_score_micro_epoch_avg: 0.716, throughput: 778109.230, loss_instantaneous: 0.909\n",
      "2022-08-12 00:06:58 INFO     Epoch 154 - Batch 30: loss: 0.907, accuracy_epoch_avg: 0.715, f1_score_macro_epoch_avg: 0.559, f1_score_micro_epoch_avg: 0.716, throughput: 828797.278, loss_instantaneous: 0.907\n",
      "2022-08-12 00:06:58 INFO     Epoch 155 - Batch 30: loss: 0.908, accuracy_epoch_avg: 0.716, f1_score_macro_epoch_avg: 0.554, f1_score_micro_epoch_avg: 0.716, throughput: 789214.037, loss_instantaneous: 0.907\n",
      "2022-08-12 00:06:58 INFO     Epoch 156 - Batch 30: loss: 0.905, accuracy_epoch_avg: 0.717, f1_score_macro_epoch_avg: 0.561, f1_score_micro_epoch_avg: 0.717, throughput: 820318.757, loss_instantaneous: 0.906\n",
      "2022-08-12 00:06:58 INFO     Epoch 157 - Batch 30: loss: 0.906, accuracy_epoch_avg: 0.717, f1_score_macro_epoch_avg: 0.556, f1_score_micro_epoch_avg: 0.717, throughput: 812676.593, loss_instantaneous: 0.907\n",
      "2022-08-12 00:06:59 INFO     Epoch 158 - Batch 30: loss: 0.905, accuracy_epoch_avg: 0.717, f1_score_macro_epoch_avg: 0.559, f1_score_micro_epoch_avg: 0.717, throughput: 800156.057, loss_instantaneous: 0.906\n",
      "2022-08-12 00:06:59 INFO     Epoch 159 - Batch 30: loss: 0.902, accuracy_epoch_avg: 0.719, f1_score_macro_epoch_avg: 0.556, f1_score_micro_epoch_avg: 0.719, throughput: 836001.339, loss_instantaneous: 0.901\n",
      "2022-08-12 00:06:59 INFO     Epoch 160 - Batch 30: loss: 0.911, accuracy_epoch_avg: 0.716, f1_score_macro_epoch_avg: 0.555, f1_score_micro_epoch_avg: 0.716, throughput: 833469.187, loss_instantaneous: 0.909\n",
      "2022-08-12 00:06:59 INFO     Epoch 161 - Batch 30: loss: 0.905, accuracy_epoch_avg: 0.719, f1_score_macro_epoch_avg: 0.558, f1_score_micro_epoch_avg: 0.719, throughput: 791842.241, loss_instantaneous: 0.905\n",
      "2022-08-12 00:06:59 INFO     Epoch 162 - Batch 30: loss: 0.908, accuracy_epoch_avg: 0.719, f1_score_macro_epoch_avg: 0.561, f1_score_micro_epoch_avg: 0.719, throughput: 813071.158, loss_instantaneous: 0.908\n",
      "2022-08-12 00:06:59 INFO     Epoch 163 - Batch 30: loss: 0.907, accuracy_epoch_avg: 0.717, f1_score_macro_epoch_avg: 0.555, f1_score_micro_epoch_avg: 0.717, throughput: 797316.032, loss_instantaneous: 0.906\n",
      "2022-08-12 00:06:59 INFO     Epoch 164 - Batch 30: loss: 0.901, accuracy_epoch_avg: 0.718, f1_score_macro_epoch_avg: 0.563, f1_score_micro_epoch_avg: 0.718, throughput: 799167.852, loss_instantaneous: 0.901\n",
      "2022-08-12 00:07:00 INFO     Epoch 165 - Batch 30: loss: 0.894, accuracy_epoch_avg: 0.719, f1_score_macro_epoch_avg: 0.561, f1_score_micro_epoch_avg: 0.719, throughput: 750463.710, loss_instantaneous: 0.895\n",
      "2022-08-12 00:07:00 INFO     Epoch 166 - Batch 30: loss: 0.901, accuracy_epoch_avg: 0.718, f1_score_macro_epoch_avg: 0.559, f1_score_micro_epoch_avg: 0.718, throughput: 796679.518, loss_instantaneous: 0.902\n",
      "2022-08-12 00:07:00 INFO     Epoch 167 - Batch 30: loss: 0.903, accuracy_epoch_avg: 0.719, f1_score_macro_epoch_avg: 0.564, f1_score_micro_epoch_avg: 0.719, throughput: 825822.341, loss_instantaneous: 0.902\n",
      "2022-08-12 00:07:00 INFO     Epoch 168 - Batch 30: loss: 0.906, accuracy_epoch_avg: 0.718, f1_score_macro_epoch_avg: 0.563, f1_score_micro_epoch_avg: 0.718, throughput: 785203.932, loss_instantaneous: 0.905\n",
      "2022-08-12 00:07:00 INFO     Epoch 169 - Batch 30: loss: 0.897, accuracy_epoch_avg: 0.719, f1_score_macro_epoch_avg: 0.560, f1_score_micro_epoch_avg: 0.719, throughput: 765243.443, loss_instantaneous: 0.898\n",
      "2022-08-12 00:07:00 INFO     Epoch 170 - Batch 30: loss: 0.892, accuracy_epoch_avg: 0.722, f1_score_macro_epoch_avg: 0.564, f1_score_micro_epoch_avg: 0.722, throughput: 828700.467, loss_instantaneous: 0.891\n",
      "2022-08-12 00:07:00 INFO     Epoch 171 - Batch 30: loss: 0.900, accuracy_epoch_avg: 0.717, f1_score_macro_epoch_avg: 0.558, f1_score_micro_epoch_avg: 0.717, throughput: 833376.621, loss_instantaneous: 0.900\n",
      "2022-08-12 00:07:00 INFO     Epoch 172 - Batch 30: loss: 0.900, accuracy_epoch_avg: 0.718, f1_score_macro_epoch_avg: 0.567, f1_score_micro_epoch_avg: 0.718, throughput: 829840.753, loss_instantaneous: 0.901\n",
      "2022-08-12 00:07:01 INFO     Epoch 173 - Batch 30: loss: 0.899, accuracy_epoch_avg: 0.719, f1_score_macro_epoch_avg: 0.562, f1_score_micro_epoch_avg: 0.719, throughput: 782606.980, loss_instantaneous: 0.899\n",
      "2022-08-12 00:07:01 INFO     Epoch 174 - Batch 30: loss: 0.892, accuracy_epoch_avg: 0.720, f1_score_macro_epoch_avg: 0.563, f1_score_micro_epoch_avg: 0.720, throughput: 822379.616, loss_instantaneous: 0.893\n",
      "2022-08-12 00:07:01 INFO     Epoch 175 - Batch 30: loss: 0.894, accuracy_epoch_avg: 0.719, f1_score_macro_epoch_avg: 0.561, f1_score_micro_epoch_avg: 0.719, throughput: 836277.267, loss_instantaneous: 0.893\n",
      "2022-08-12 00:07:01 INFO     Epoch 176 - Batch 30: loss: 0.896, accuracy_epoch_avg: 0.720, f1_score_macro_epoch_avg: 0.564, f1_score_micro_epoch_avg: 0.720, throughput: 823556.443, loss_instantaneous: 0.897\n",
      "2022-08-12 00:07:01 INFO     Epoch 177 - Batch 30: loss: 0.896, accuracy_epoch_avg: 0.719, f1_score_macro_epoch_avg: 0.558, f1_score_micro_epoch_avg: 0.719, throughput: 825672.058, loss_instantaneous: 0.895\n",
      "2022-08-12 00:07:01 INFO     Epoch 178 - Batch 30: loss: 0.900, accuracy_epoch_avg: 0.717, f1_score_macro_epoch_avg: 0.561, f1_score_micro_epoch_avg: 0.717, throughput: 809466.624, loss_instantaneous: 0.899\n",
      "2022-08-12 00:07:01 INFO     Epoch 179 - Batch 30: loss: 0.892, accuracy_epoch_avg: 0.720, f1_score_macro_epoch_avg: 0.560, f1_score_micro_epoch_avg: 0.720, throughput: 804423.551, loss_instantaneous: 0.892\n",
      "2022-08-12 00:07:01 INFO     Epoch 180 - Batch 30: loss: 0.893, accuracy_epoch_avg: 0.720, f1_score_macro_epoch_avg: 0.572, f1_score_micro_epoch_avg: 0.720, throughput: 828753.271, loss_instantaneous: 0.892\n",
      "2022-08-12 00:07:01 INFO     Epoch 181 - Batch 30: loss: 0.896, accuracy_epoch_avg: 0.719, f1_score_macro_epoch_avg: 0.565, f1_score_micro_epoch_avg: 0.719, throughput: 819133.962, loss_instantaneous: 0.895\n",
      "2022-08-12 00:07:02 INFO     Epoch 182 - Batch 30: loss: 0.895, accuracy_epoch_avg: 0.719, f1_score_macro_epoch_avg: 0.561, f1_score_micro_epoch_avg: 0.719, throughput: 801049.671, loss_instantaneous: 0.895\n",
      "2022-08-12 00:07:02 INFO     Epoch 183 - Batch 30: loss: 0.892, accuracy_epoch_avg: 0.722, f1_score_macro_epoch_avg: 0.566, f1_score_micro_epoch_avg: 0.722, throughput: 834508.403, loss_instantaneous: 0.892\n",
      "2022-08-12 00:07:02 INFO     Epoch 184 - Batch 30: loss: 0.896, accuracy_epoch_avg: 0.721, f1_score_macro_epoch_avg: 0.556, f1_score_micro_epoch_avg: 0.721, throughput: 789662.844, loss_instantaneous: 0.896\n",
      "2022-08-12 00:07:02 INFO     Epoch 185 - Batch 30: loss: 0.893, accuracy_epoch_avg: 0.720, f1_score_macro_epoch_avg: 0.566, f1_score_micro_epoch_avg: 0.721, throughput: 832576.428, loss_instantaneous: 0.892\n",
      "2022-08-12 00:07:02 INFO     Epoch 186 - Batch 30: loss: 0.892, accuracy_epoch_avg: 0.720, f1_score_macro_epoch_avg: 0.565, f1_score_micro_epoch_avg: 0.720, throughput: 819274.993, loss_instantaneous: 0.892\n",
      "2022-08-12 00:07:02 INFO     Epoch 187 - Batch 30: loss: 0.891, accuracy_epoch_avg: 0.721, f1_score_macro_epoch_avg: 0.562, f1_score_micro_epoch_avg: 0.721, throughput: 815385.277, loss_instantaneous: 0.891\n",
      "2022-08-12 00:07:02 INFO     Epoch 188 - Batch 30: loss: 0.891, accuracy_epoch_avg: 0.721, f1_score_macro_epoch_avg: 0.571, f1_score_micro_epoch_avg: 0.721, throughput: 789840.272, loss_instantaneous: 0.890\n",
      "2022-08-12 00:07:02 INFO     Epoch 189 - Batch 30: loss: 0.889, accuracy_epoch_avg: 0.720, f1_score_macro_epoch_avg: 0.564, f1_score_micro_epoch_avg: 0.720, throughput: 820389.470, loss_instantaneous: 0.889\n",
      "2022-08-12 00:07:03 INFO     Epoch 190 - Batch 30: loss: 0.889, accuracy_epoch_avg: 0.720, f1_score_macro_epoch_avg: 0.568, f1_score_micro_epoch_avg: 0.720, throughput: 802289.903, loss_instantaneous: 0.888\n",
      "2022-08-12 00:07:03 INFO     Epoch 191 - Batch 30: loss: 0.895, accuracy_epoch_avg: 0.718, f1_score_macro_epoch_avg: 0.565, f1_score_micro_epoch_avg: 0.718, throughput: 785444.179, loss_instantaneous: 0.895\n",
      "2022-08-12 00:07:03 INFO     Epoch 192 - Batch 30: loss: 0.891, accuracy_epoch_avg: 0.718, f1_score_macro_epoch_avg: 0.563, f1_score_micro_epoch_avg: 0.718, throughput: 822117.978, loss_instantaneous: 0.891\n",
      "2022-08-12 00:07:03 INFO     Epoch 193 - Batch 30: loss: 0.890, accuracy_epoch_avg: 0.720, f1_score_macro_epoch_avg: 0.567, f1_score_micro_epoch_avg: 0.720, throughput: 824257.540, loss_instantaneous: 0.889\n",
      "2022-08-12 00:07:03 INFO     Epoch 194 - Batch 30: loss: 0.891, accuracy_epoch_avg: 0.720, f1_score_macro_epoch_avg: 0.564, f1_score_micro_epoch_avg: 0.720, throughput: 837972.655, loss_instantaneous: 0.892\n",
      "2022-08-12 00:07:03 INFO     Epoch 195 - Batch 30: loss: 0.884, accuracy_epoch_avg: 0.720, f1_score_macro_epoch_avg: 0.571, f1_score_micro_epoch_avg: 0.720, throughput: 811186.463, loss_instantaneous: 0.885\n",
      "2022-08-12 00:07:03 INFO     Epoch 196 - Batch 30: loss: 0.892, accuracy_epoch_avg: 0.722, f1_score_macro_epoch_avg: 0.565, f1_score_micro_epoch_avg: 0.722, throughput: 816231.286, loss_instantaneous: 0.891\n",
      "2022-08-12 00:07:03 INFO     Epoch 197 - Batch 30: loss: 0.887, accuracy_epoch_avg: 0.721, f1_score_macro_epoch_avg: 0.570, f1_score_micro_epoch_avg: 0.721, throughput: 835160.348, loss_instantaneous: 0.887\n",
      "2022-08-12 00:07:04 INFO     Epoch 198 - Batch 30: loss: 0.887, accuracy_epoch_avg: 0.720, f1_score_macro_epoch_avg: 0.563, f1_score_micro_epoch_avg: 0.720, throughput: 792976.743, loss_instantaneous: 0.888\n",
      "2022-08-12 00:07:04 INFO     Epoch 199 - Batch 30: loss: 0.886, accuracy_epoch_avg: 0.722, f1_score_macro_epoch_avg: 0.567, f1_score_micro_epoch_avg: 0.722, throughput: 819347.248, loss_instantaneous: 0.886\n",
      "2022-08-12 00:07:04 INFO     Epoch 200 - Batch 30: loss: 0.883, accuracy_epoch_avg: 0.721, f1_score_macro_epoch_avg: 0.571, f1_score_micro_epoch_avg: 0.721, throughput: 821761.310, loss_instantaneous: 0.883\n",
      "2022-08-12 00:07:04 INFO     Mean throughput for training: 807389.7025896562, STD throughput for training: 26930.228361563342, Mean throughput over real nodes (no padding) for training: 789259.668313511\n",
      "2022-08-12 00:07:04 INFO     \n",
      "Saving checkpoint to: /notebooks/get-started/checkpoints/Cluster-GCN-ogbn-arxiv-fp16-ipu-AdjacencyForm.SPARSE_TUPLE-20220812_000306/final.h5\n",
      "2022-08-12 00:07:04 INFO     Training complete\n"
     ]
    }
   ],
   "source": [
    "# Seed the random generators for reproducibility\n",
    "set_random_seeds(config.seed)\n",
    "\n",
    "with strategy_training_scope:\n",
    "    # Create the model for training\n",
    "    model_training = create_model(\n",
    "        micro_batch_size=config.training.micro_batch_size,\n",
    "        num_labels=dataset.num_labels,\n",
    "        num_features=dataset.num_features,\n",
    "        max_nodes_per_batch=training_clusters.max_nodes_per_batch,\n",
    "        max_edges_per_batch=training_clusters.max_edges_per_batch,\n",
    "        hidden_size=config.model.hidden_size,\n",
    "        num_layers=config.model.num_layers,\n",
    "        dropout_rate=config.model.dropout,\n",
    "        adjacency_params=config.model.adjacency.dict(),\n",
    "        cast_model_inputs_to_dtype=precision.cast_model_inputs_to_dtype,\n",
    "        first_layer_precalculation=config.model.first_layer_precalculation,\n",
    "        use_ipu_layers=(config.training.device == \"ipu\"),\n",
    "        adjacency_form=adjacency_form_training\n",
    "    )\n",
    "    model_training.summary(print_fn=logging.info)\n",
    "\n",
    "    # Set options for the infeed and outfeed buffers that connect IPU and host.\n",
    "    model_training.set_infeed_queue_options(prefetch_depth=10)\n",
    "    model_training.set_outfeed_queue_options(buffer_depth=10)\n",
    "\n",
    "    if num_pipeline_stages_training > 1 and config.training.device == \"ipu\":\n",
    "        # Pipeline the model if required\n",
    "        pipeline_model(model=model_training,\n",
    "                       config=config.training,\n",
    "                       pipeline_names=PIPELINE_NAMES,\n",
    "                       pipeline_allocate_previous=PIPELINE_ALLOCATE_PREVIOUS,\n",
    "                       num_ipus_per_replica=num_ipus_per_replica_training,\n",
    "                       matmul_partials_type=precision.matmul_partials_type)\n",
    "    elif config.training.gradient_accumulation_steps_per_replica > 1:\n",
    "        # Set gradient accumulation if requested. If the model is pipelined\n",
    "        # this is done through the pipeline API above.\n",
    "        model_training.set_gradient_accumulation_options(\n",
    "            gradient_accumulation_steps_per_replica=\n",
    "            config.training.gradient_accumulation_steps_per_replica\n",
    "        )\n",
    "\n",
    "    # Build the loss function and other metrics\n",
    "    loss, accuracy, f1_score_macro, f1_score_micro = get_loss_and_metrics(\n",
    "        task=dataset.task,\n",
    "        num_labels=dataset.num_labels,\n",
    "        adjacency_form=adjacency_form_training,\n",
    "        metrics_precision=precision.metrics_precision,\n",
    "        enable_loss_outfeed=(config.training.device == \"ipu\"))\n",
    "\n",
    "    # Build the optimizer\n",
    "    optimizer = get_optimizer(\n",
    "        gradient_accumulation_steps_per_replica=config.training.gradient_accumulation_steps_per_replica,\n",
    "        num_replicas=config.training.replicas,\n",
    "        learning_rate=tf.cast(config.training.lr, dtype=tf.float32),\n",
    "        loss_scaling=config.training.loss_scaling,\n",
    "        optimizer_compute_precision=precision.optimizer_compute_precision\n",
    "    )\n",
    "\n",
    "    # Compile the model\n",
    "    model_training.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=loss,\n",
    "        metrics=[accuracy, f1_score_macro, f1_score_micro],\n",
    "        steps_per_execution=batch_config_training.steps_per_execution,\n",
    "    )\n",
    "\n",
    "    # Create any callbacks required for training\n",
    "    callbacks_training = CallbackFactory.get_callbacks(\n",
    "        universal_run_name=universal_run_name,\n",
    "        num_nodes_processed_per_execution=batch_config_training.num_nodes_processed_per_execution,\n",
    "        real_over_padded_ratio=batch_config_training.real_over_padded_ratio,\n",
    "        total_num_epochs=batch_config_training.scaled_num_epochs,\n",
    "        checkpoint_path=config.save_ckpt_path.joinpath(universal_run_name),\n",
    "        config=config.dict(),\n",
    "        executions_per_log=config.executions_per_log,\n",
    "        executions_per_ckpt=config.executions_per_ckpt,\n",
    "        outfeed_queues=[loss.outfeed_queue]\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    model_training.fit(\n",
    "        data_generator_training,\n",
    "        epochs=batch_config_training.scaled_num_epochs,\n",
    "        steps_per_epoch=batch_config_training.steps_per_epoch,\n",
    "        callbacks=callbacks_training,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "trained_weights = model_training.get_weights()\n",
    "logging.info(\"Training complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee661da",
   "metadata": {},
   "source": [
    "## Test the trained model\n",
    "\n",
    "Once we have trained the model, let's evaluate how it performs on the test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a805336c",
   "metadata": {},
   "source": [
    "### Test configuration\n",
    "\n",
    "Note we usually have different requirements for testing than training. For example, while we may want to train the model with FP16 arithmetic for reduced memory and increased throughput, we typically want to test the model with FP32 to avoid loosing accuracy.\n",
    "\n",
    "Here, again, we use the values from the config file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "74b7c014",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-12T00:07:04.409959Z",
     "iopub.status.busy": "2022-08-12T00:07:04.409773Z",
     "iopub.status.idle": "2022-08-12T00:07:04.414509Z",
     "shell.execute_reply": "2022-08-12T00:07:04.413791Z",
     "shell.execute_reply.started": "2022-08-12T00:07:04.409939Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set the precision policy for testing\n",
    "precision = Precision(config.test.precision)\n",
    "tf.keras.mixed_precision.set_global_policy(precision.policy)\n",
    "\n",
    "# Set how the adjacency matrix is expressed,\n",
    "# namely dense tensor, sparse tensor, or tuple.\n",
    "adjacency_form_test = get_adjacency_form(\n",
    "    config.test.device,\n",
    "    config.test.use_sparse_representation)\n",
    "# Decide on the dtype of the adjacency matrix\n",
    "adjacency_dtype_test = get_adjacency_dtype(\n",
    "    config.test.device,\n",
    "    config.test.use_sparse_representation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd37f9e6",
   "metadata": {},
   "source": [
    "### Cluster test dataset\n",
    "\n",
    "Since the test dataset is different from the training dataset, it has also to be clustered independently.\n",
    "\n",
    "In practice, we want to evaluate the performance of the trained model on the full test graph, so no artefacts are introduced while measuring the accuracy. Note that evaluation only requires a forward pass per batch, which is computationally much less demanding that the multiple forward and backward passes per batch required during training. Hence, we usually can afford testing the model on the CPU, which though slower, usually has lots of memory available.\n",
    "\n",
    "In the case the graph dataset is too large so that it doesn't fit even on CPU memory, we just have to cluster the test dataset.\n",
    "\n",
    "In any case, we use the same `ClusterGraph` class that we used for the training set, since it is convenient to compute and store the maximum number of nodes and edges per batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a4652e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-12T00:07:04.415402Z",
     "iopub.status.busy": "2022-08-12T00:07:04.415223Z",
     "iopub.status.idle": "2022-08-12T00:07:48.493908Z",
     "shell.execute_reply": "2022-08-12T00:07:48.493114Z",
     "shell.execute_reply.started": "2022-08-12T00:07:04.415385Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-12 00:07:04 INFO     Unable to find full clustering cache.\n",
      "2022-08-12 00:07:04 INFO     Clustering graph with name ogbn-arxiv-test...\n",
      "2022-08-12 00:07:04 INFO     Nodes to edges balance ratio is set to None. This will mean metis will cluster attempting to balance the number of nodes in each cluster.\n",
      "2022-08-12 00:07:47 INFO     Clustering completed in 42.858 seconds.\n",
      "2022-08-12 00:07:47 INFO     Saving clusters in /notebooks/get-started/graph_datasets/clusters-ogbn-arxiv-test-SPARSE_TENSOR-UPPER_BOUND-UPPER_BOUND-0.0-None-20-num_clusters-1500.npy...\n",
      "2022-08-12 00:07:47 INFO     Number of clusters (1500) provided, inferred max nodes per batch 2320 given the dataset size (169343 nodes) and clusters per batch (20).\n",
      "2022-08-12 00:07:47 INFO     Saving max_nodes_per_batch in /notebooks/get-started/graph_datasets/max_nodes_per_batch-ogbn-arxiv-test-SPARSE_TENSOR-UPPER_BOUND-UPPER_BOUND-0.0-None-20-num_clusters-1500.npy...\n",
      "2022-08-12 00:07:47 INFO     Counting the number of edges per cluster...\n",
      "100%|██████████| 1500/1500 [00:00<00:00, 2458.09it/s]\n",
      "2022-08-12 00:07:48 INFO     Inferred max num edges per batch 56730, given number of clusters (1500) and clusters per batch (20). This includes room for inter-cluster and self-loop edges.\n",
      "2022-08-12 00:07:48 INFO     Saving max_edges_per_batch in /notebooks/get-started/graph_datasets/max_edges_per_batch-ogbn-arxiv-test-SPARSE_TENSOR-UPPER_BOUND-UPPER_BOUND-0.0-None-20-num_clusters-1500.npy...\n"
     ]
    }
   ],
   "source": [
    "# Cluster the test graph\n",
    "test_clusters = ClusterGraph(\n",
    "    adjacency=dataset.adjacency_full,\n",
    "    num_clusters=config.test.num_clusters,\n",
    "    visible_nodes=np.arange(dataset.total_num_nodes),\n",
    "    max_nodes_per_batch=config.test.max_nodes_per_batch,\n",
    "    clusters_per_batch=config.test.clusters_per_batch,\n",
    "    dataset_name=config.dataset_name + \"-test\",\n",
    "    cache_dir=config.data_path,\n",
    "    regenerate_cluster_cache=config.regenerate_clustering_cache,\n",
    "    save_clustering_cache=config.save_clustering_cache,\n",
    "    directed_graph=(dataset.graph_type == GraphType.DIRECTED),\n",
    "    adjacency_form=adjacency_form_test,\n",
    "    inter_cluster_ratio=config.inter_cluster_ratio,\n",
    "    method_max_nodes=method_max_nodes,\n",
    "    method_max_edges=method_max_edges,\n",
    "    node_edge_imbalance_ratio=config.cluster_node_edge_imbalance_ratio\n",
    ")\n",
    "test_clusters.cluster_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8696a8d5",
   "metadata": {},
   "source": [
    "## Test dataset generator\n",
    "\n",
    "Create an efficient dataset generator that can feed the Keras Model.evaluate method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e58ddbb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-12T00:07:48.495231Z",
     "iopub.status.busy": "2022-08-12T00:07:48.494916Z",
     "iopub.status.idle": "2022-08-12T00:07:48.646626Z",
     "shell.execute_reply": "2022-08-12T00:07:48.645807Z",
     "shell.execute_reply.started": "2022-08-12T00:07:48.495208Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-12 00:07:48 INFO     Created batch generator for test: <PrefetchDataset shapes: ({adjacency_batch: (2320, 2320), features_batch: (2320, 256)}, (2320, 1)), types: ({adjacency_batch: tf.float32, features_batch: tf.float16}, tf.int32)>\n"
     ]
    }
   ],
   "source": [
    "data_generator_test = tf_dataset_generator(\n",
    "    adjacency=dataset.adjacency_full,\n",
    "    clusters=test_clusters.clusters,\n",
    "    features=dataset.features,\n",
    "    labels=dataset.labels,\n",
    "    mask=dataset.mask_test,\n",
    "    num_clusters=config.test.num_clusters,\n",
    "    clusters_per_batch=config.test.clusters_per_batch,\n",
    "    max_nodes_per_batch=test_clusters.max_nodes_per_batch,\n",
    "    max_edges_per_batch=test_clusters.max_edges_per_batch,\n",
    "    adjacency_dtype=adjacency_dtype_test,\n",
    "    adjacency_form=adjacency_form_test,\n",
    "    micro_batch_size=config.test.micro_batch_size,\n",
    "    seed=config.seed\n",
    ")\n",
    "logging.info(\n",
    "    f\"Created batch generator for test: {data_generator_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde1e67f",
   "metadata": {},
   "source": [
    "Since there is only one cluster or subgraph (the whole graph) and there is no distributed training, we do not need to create a batch config object when testing on the CPU.\n",
    "\n",
    "We do not have to create a strategy when testing on the CPU either, since this is the default device for TensorFlow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591d66e3",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "Create the model for test that will run on the CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5da36bfb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-12T00:07:48.647907Z",
     "iopub.status.busy": "2022-08-12T00:07:48.647594Z",
     "iopub.status.idle": "2022-08-12T00:07:48.771186Z",
     "shell.execute_reply": "2022-08-12T00:07:48.770277Z",
     "shell.execute_reply.started": "2022-08-12T00:07:48.647884Z"
    }
   },
   "outputs": [],
   "source": [
    "set_random_seeds(config.seed + 1)\n",
    "\n",
    "model_test = create_model(\n",
    "    micro_batch_size=config.test.micro_batch_size,\n",
    "    num_labels=dataset.num_labels,\n",
    "    num_features=dataset.num_features,\n",
    "    max_nodes_per_batch=test_clusters.max_nodes_per_batch,\n",
    "    max_edges_per_batch=test_clusters.max_edges_per_batch,\n",
    "    hidden_size=config.model.hidden_size,\n",
    "    num_layers=config.model.num_layers,\n",
    "    dropout_rate=config.model.dropout,\n",
    "    adjacency_params=config.model.adjacency.dict(),\n",
    "    cast_model_inputs_to_dtype=precision.cast_model_inputs_to_dtype,\n",
    "    first_layer_precalculation=config.model.first_layer_precalculation,\n",
    "    use_ipu_layers=(config.test.device == \"ipu\"),\n",
    "    adjacency_form=adjacency_form_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdffbe65",
   "metadata": {},
   "source": [
    "Copy the weights from training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e8d9e0df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-12T00:07:48.774013Z",
     "iopub.status.busy": "2022-08-12T00:07:48.773697Z",
     "iopub.status.idle": "2022-08-12T00:07:48.780453Z",
     "shell.execute_reply": "2022-08-12T00:07:48.779737Z",
     "shell.execute_reply.started": "2022-08-12T00:07:48.773991Z"
    }
   },
   "outputs": [],
   "source": [
    "model_test.set_weights(trained_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72eeff3d",
   "metadata": {},
   "source": [
    "Get the loss function and other metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "51b20ce2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-12T00:07:48.781629Z",
     "iopub.status.busy": "2022-08-12T00:07:48.781310Z",
     "iopub.status.idle": "2022-08-12T00:07:48.810835Z",
     "shell.execute_reply": "2022-08-12T00:07:48.810087Z",
     "shell.execute_reply.started": "2022-08-12T00:07:48.781608Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-12 00:07:48 INFO     Using loss and accuracy for multi class classification task.\n"
     ]
    }
   ],
   "source": [
    "_, accuracy, f1_score_macro, f1_score_micro = get_loss_and_metrics(\n",
    "    task=dataset.task,\n",
    "    num_labels=dataset.num_labels,\n",
    "    adjacency_form=adjacency_form_test,\n",
    "    metrics_precision=precision.metrics_precision,\n",
    "    enable_loss_outfeed=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66148137",
   "metadata": {},
   "source": [
    "Compile the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1d330dd9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-12T00:07:48.811964Z",
     "iopub.status.busy": "2022-08-12T00:07:48.811661Z",
     "iopub.status.idle": "2022-08-12T00:07:48.819281Z",
     "shell.execute_reply": "2022-08-12T00:07:48.818568Z",
     "shell.execute_reply.started": "2022-08-12T00:07:48.811940Z"
    }
   },
   "outputs": [],
   "source": [
    "model_test.compile(metrics=[accuracy, f1_score_macro, f1_score_micro],\n",
    "                   steps_per_execution=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0223c593",
   "metadata": {},
   "source": [
    "Run test on the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d2d13cc7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-12T00:07:48.820428Z",
     "iopub.status.busy": "2022-08-12T00:07:48.820101Z",
     "iopub.status.idle": "2022-08-12T00:07:49.222103Z",
     "shell.execute_reply": "2022-08-12T00:07:49.220816Z",
     "shell.execute_reply.started": "2022-08-12T00:07:48.820404Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 367ms/step - loss: 0.0000e+00 - accuracy_epoch_avg: 0.7367 - f1_score_macro_epoch_avg: 0.2536 - f1_score_micro_epoch_avg: 0.7367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-12 00:07:49 INFO     Test Accuracy: 0.7366771101951599, Test F1 macro: 0.2536095976829529, Test F1 micro: 0.7366770505905151\n",
      "2022-08-12 00:07:49 INFO     Test complete\n"
     ]
    }
   ],
   "source": [
    "results = model_test.evaluate(data_generator_test,\n",
    "                              steps=1)\n",
    "\n",
    "logging.info(f\"Test Accuracy: {results[1]},\"\n",
    "             f\" Test F1 macro: {results[2]},\"\n",
    "             f\" Test F1 micro: {results[3]}\")\n",
    "logging.info(\"Test complete\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "traceability": {
   "sdk_version": "2.6.0+1069",
   "source_file": "run_cluster_gcn_notebook.py",
   "sst_version": "0.0.7",
   "timestamp": "2022-07-21T19:14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
